import streamlit as st
import pandas as pd
import json
import uuid
import time
import os
import copy
import re
from datetime import datetime, timedelta

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="IATF å®¡è®¡è½¬æ¢å·¥å…· (v44.0)",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# --- 1. ä¾§è¾¹æ ï¼šæ¨¡æ¿åŠ è½½ä¸èåˆé€»è¾‘ ---
with st.sidebar:
    st.header("âš™ï¸ æ¨¡æ¿é…ç½®")
    
    base_template = None
    if os.path.exists('é‡‘ç£.json'):
        try:
            with open('é‡‘ç£.json', 'r', encoding='utf-8') as f:
                base_template = json.load(f)
            st.success("âœ… å·²åŠ è½½æ ‡å‡†åº•åº§: `é‡‘ç£.json`")
        except Exception as e:
            st.error(f"âŒ è¯»å– `é‡‘ç£.json` å¤±è´¥: {e}")
            st.stop()
    else:
        st.error("âŒ æ‰¾ä¸åˆ°æ ‡å‡†åº•åº§ `é‡‘ç£.json`ï¼è¯·ç¡®ä¿å®ƒåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚")
        st.stop()

    st.info("ğŸ’¡ è¯·ä¸Šä¼ æ‚¨çš„æ¨¡æ¿ã€‚ç¨‹åºå°†æå–å…¶ä¸­çš„ Stage1 èŠ‚ç‚¹æ¥æ›¿æ¢åº•åº§ã€‚")
    user_template_file = st.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰ JSON æ¨¡æ¿", type=["json"])
    
    user_template_data = None
    if user_template_file:
        try:
            user_template_data = json.load(user_template_file)
            st.success(f"âœ… æˆåŠŸåŠ è½½è‡ªå®šä¹‰æ¨¡æ¿: {user_template_file.name}")
        except Exception as e:
            st.error(f"âŒ è‡ªå®šä¹‰æ¨¡æ¿è§£æå¤±è´¥: {e}")
            st.stop()
    else:
        st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  JSON æ¨¡æ¿æ–‡ä»¶ã€‚")
        st.stop()

# --- è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨å¯»å€ ---
def ensure_path(d, path):
    current = d
    for key in path:
        if key not in current or not isinstance(current[key], dict):
            current[key] = {}
        current = current[key]
    return current

def safe_get(obj, key, default=""):
    if isinstance(obj, dict):
        return obj.get(key, default)
    return default

# --- æ ¸å¿ƒè½¬æ¢é€»è¾‘ ---
def generate_json_logic(excel_file, base_data, user_data):
    final_json = copy.deepcopy(base_data)
    
    for key in ["Stage1Activities", "Stage1Part1", "Stage1Part2"]:
        if key in user_data:
            final_json[key] = copy.deepcopy(user_data[key])
    
    try:
        xls = pd.ExcelFile(excel_file)
        db_df = pd.read_excel(xls, sheet_name='æ•°æ®åº“', header=None) if 'æ•°æ®åº“' in xls.sheet_names else pd.read_excel(xls, sheet_name=0, header=None)
        proc_df = pd.read_excel(xls, sheet_name='è¿‡ç¨‹æ¸…å•') if 'è¿‡ç¨‹æ¸…å•' in xls.sheet_names else pd.DataFrame()
        info_df = pd.read_excel(xls, sheet_name='ä¿¡æ¯', header=None) if 'ä¿¡æ¯' in xls.sheet_names else pd.DataFrame()
        doc_list_df = pd.read_excel(xls, sheet_name=xls.sheet_names[8], header=None) if len(xls.sheet_names) >= 9 else pd.DataFrame()
    except Exception as e:
        raise ValueError(f"Excel è¯»å–å¤±è´¥: {str(e)}")

    def find_val_by_key(df, keywords, col_offset=1):
        if df.empty: return ""
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                cell_val = str(df.iloc[r, c]).strip()
                for k in keywords:
                    if k in cell_val:
                        if c + col_offset < df.shape[1]:
                            return str(df.iloc[r, c + col_offset]).strip()
        return ""
        
    def get_db_val(r, c):
        try:
            val = db_df.iloc[r, c]
            return str(val).strip() if pd.notna(val) else ""
        except: return ""

    # ================= 2. æ•°æ®æå– =================
    
    # [å§“å]
    raw_name_full = find_val_by_key(db_df, ["å§“å", "Auditor Name"]) or get_db_val(5, 1)
    raw_name = raw_name_full.replace("å§“å:", "").replace("Name:", "").strip() if raw_name_full else ""
    auditor_name = raw_name
    english_part = re.sub(r'[\u4e00-\u9fff]', '', raw_name).strip()
    if english_part:
        parts = english_part.split()
        if len(parts) >= 2 and parts[0].isupper() and not parts[1].isupper(): auditor_name = f"{parts[1]} {parts[0]}"
        else: auditor_name = english_part

    # [CCAA]
    ccaa_raw = find_val_by_key(db_df, ["å®¡æ ¸å‘˜CCAA", "CCAA"]) or get_db_val(4, 1)
    caa_no = ""
    if ccaa_raw:
        match = re.search(r'(?:CCAA[:ï¼š\s-])\s*(.*)', ccaa_raw, re.IGNORECASE | re.DOTALL)
        caa_no = match.group(1).strip() if match else ccaa_raw.strip()

    # [AuditorId]
    auditor_id = ""
    if not info_df.empty:
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                cell_text = str(info_df.iloc[r, c])
                if "IATF Card" in cell_text or "IATFå¡å·" in cell_text:
                    if c + 1 < info_df.shape[1]:
                        raw_val = str(info_df.iloc[r, c + 1]).strip()
                        raw_val = raw_val.replace('\n', ' ').replace('\r', ' ')
                        auditor_id = re.sub(r'^IATF[:ï¼š\s-]*', '', raw_val, flags=re.IGNORECASE).strip()
                        if len(auditor_id) > 4: break
            if auditor_id and len(auditor_id) > 4: break

    # [æ—¥æœŸ]
    start_date_raw = find_val_by_key(db_df, ["å®¡æ ¸å¼€å§‹æ—¥æœŸ", "å®¡æ ¸å¼€å§‹æ—¶é—´"]) or get_db_val(2, 1)
    end_date_raw = find_val_by_key(db_df, ["å®¡æ ¸ç»“æŸæ—¥æœŸ", "å®¡æ ¸ç»“æŸæ—¶é—´"]) or get_db_val(3, 1)
    
    def fmt_iso(val):
        try:
            clean_val = str(val).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
            dt = pd.to_datetime(clean_val, errors='coerce')
            if pd.notna(dt): return dt.strftime('%Y-%m-%d') + "T00:00:00.000Z"
        except: pass
        return ""
        
    start_iso, end_iso = fmt_iso(start_date_raw), fmt_iso(end_date_raw)
    
    next_audit_iso = ""
    try:
        clean_end = str(end_date_raw).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
        end_dt = pd.to_datetime(clean_end, errors='coerce')
        if pd.notna(end_dt): next_audit_iso = (end_dt + timedelta(days=45)).strftime('%Y-%m-%d') + "T00:00:00.000Z"
    except: pass

    # [é¡¾å®¢ä¸ CSR]
    customer_name = find_val_by_key(db_df, ["é¡¾å®¢", "å®¢æˆ·åç§°"]) or get_db_val(29, 1)
    supplier_code = find_val_by_key(db_df, ["ä¾›åº”å•†ç¼–ç ", "ä¾›åº”å•†ä»£ç "]) or get_db_val(30, 1)
    csr_name = find_val_by_key(db_df, ["CSRæ–‡ä»¶åç§°"]) or get_db_val(31, 1)
    csr_date_raw = find_val_by_key(db_df, ["CSRæ–‡ä»¶æ—¥æœŸ"]) or get_db_val(32, 1)
    csr_date = fmt_iso(csr_date_raw)

    # ğŸ’¥ [ä¸­è‹±æ–‡åœ°å€åˆ†ç¦»ä¸æ™ºèƒ½æå–ï¼ˆç ´æ¡ˆä¿®å¤ç‰ˆï¼‰]
    def is_chinese(s): return bool(re.search(r'[\u4e00-\u9fff]', s))
    
    native_street = ""
    english_address = ""

    # 1. ä¼˜å…ˆæ‰«æä¿¡æ¯è¡¨ï¼ˆä¸ä¼šè¢«å…¶ä»–å˜é‡å¹²æ‰°æå‰ä¸­æ–­ï¼‰
    if not info_df.empty:
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                val = str(info_df.iloc[r, c]).strip()
                if "å®¡æ ¸åœ°å€" in val or "Audit Address" in val:
                    if c + 1 < info_df.shape[1]:
                        rv = str(info_df.iloc[r, c+1]).strip()
                        if rv and rv.lower() != 'nan':
                            lines = rv.replace('\r', '\n').split('\n')
                            en_lines = [l.strip() for l in lines if not is_chinese(l) and l.strip()]
                            zh_lines = [l.strip() for l in lines if is_chinese(l) and l.strip()]
                            if en_lines: english_address = " ".join(en_lines)
                            if zh_lines: native_street = " ".join(zh_lines)
                        break

    # 2. å¦‚æœä¿¡æ¯è¡¨é‡Œæ²¡æ‰¾åˆ°ï¼Œå†å»æ•°æ®åº“å…œåº•
    if not native_street or not english_address:
        db_candidates = [get_db_val(11, 1), get_db_val(11, 4)]
        zh_cands = [c for c in db_candidates if c and is_chinese(c)]
        en_cands = [c for c in db_candidates if c and not is_chinese(c)]
        if not native_street and zh_cands: native_street = max(zh_cands, key=len)
        if not english_address and en_cands: english_address = max(en_cands, key=len)

    # å€’åºåˆ‡åˆ†
    street, city, state, country = english_address, "", "", ""
    if english_address:
        clean_eng = english_address.replace('ï¼Œ', ',')
        parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
        if len(parts) >= 3:
            country = parts[-1]
            state = parts[-2]
            city = parts[-3]
            street = ", ".join(parts[:-3])
        else:
            street = english_address

    # ================= 3. å®šç‚¹æ›¿æ¢å…¥ final_json =================

    final_json["uuid"] = str(uuid.uuid4())
    final_json["created"] = int(time.time() * 1000)

    # A. å®¡æ ¸æ•°æ®
    ensure_path(final_json, ["AuditData", "AuditDate"])
    if start_iso: final_json["AuditData"]["AuditDate"]["Start"] = start_iso
    if end_iso: final_json["AuditData"]["AuditDate"]["End"] = end_iso
    final_json["AuditData"]["CbIdentificationNo"] = find_val_by_key(db_df, ["è®¤è¯æœºæ„æ ‡è¯†å·"]) or get_db_val(2, 4)

    if "AuditTeam" not in final_json["AuditData"] or not isinstance(final_json["AuditData"]["AuditTeam"], list) or len(final_json["AuditData"]["AuditTeam"]) == 0:
        final_json["AuditData"]["AuditTeam"] = [{}]
        
    team = final_json["AuditData"]["AuditTeam"][0]
    if isinstance(team, dict):
        team.update({
            "Name": auditor_name,
            "CaaNo": caa_no,
            "AuditorId": auditor_id, 
            "AuditDaysPerformed": 1.5,
            "DatesOnSite": [{"Date": start_iso, "Day": 1}, {"Date": end_iso, "Day": 0.5}]
        })

    # B. ç»„ç»‡ä¸åœ°å€ä¿¡æ¯ 
    ensure_path(final_json, ["OrganizationInformation", "AddressNative"])
    ensure_path(final_json, ["OrganizationInformation", "Address"])
    
    org = final_json["OrganizationInformation"]
    
    org["OrganizationName"] = find_val_by_key(db_df, ["ç»„ç»‡åç§°"]) or get_db_val(1, 4)
    org["IndustryCode"] = find_val_by_key(db_df, ["è¡Œä¸šä»£ç ", "Industry Code"])
    org["IATF_USI"] = find_val_by_key(db_df, ["IATF USI", "USI"]) or get_db_val(3, 4)
    org["TotalNumberEmployees"] = find_val_by_key(db_df, ["åŒ…æ‹¬æ‰©å±•ç°åœºåœ¨å†…çš„å‘˜å·¥æ€»æ•°", "å‘˜å·¥æ€»æ•°"]) or get_db_val(27, 1)
    org["CertificateScope"] = find_val_by_key(db_df, ["è¯ä¹¦èŒƒå›´"])
    
    org["Representative"] = find_val_by_key(db_df, ["ç»„ç»‡ä»£è¡¨", "ç®¡ç†è€…ä»£è¡¨", "è”ç³»äºº", "Representative"]) or get_db_val(15, 1)
    org["Telephone"] = find_val_by_key(db_df, ["è”ç³»ç”µè¯", "ç”µè¯", "Telephone"]) or get_db_val(15, 4)
    extracted_email = find_val_by_key(db_df, ["ç”µå­é‚®ç®±", "é‚®ç®±", "Email", "E-mail"]) or get_db_val(16, 1)
    org["Email"] = "" if str(extracted_email).strip() == "0" else extracted_email
    
    if "LanguageByManufacturingPersonnel" in org:
        lang_node = org["LanguageByManufacturingPersonnel"]
        if isinstance(lang_node, list) and len(lang_node) > 0:
            if isinstance(lang_node[0], dict):
                lang_node[0]["Products"] = ""
        elif isinstance(lang_node, dict):
            if "0" in lang_node and isinstance(lang_node["0"], dict):
                lang_node["0"]["Products"] = ""
            else:
                lang_node["Products"] = ""
    
    org["AddressNative"].update({
        "Street1": native_street,
        "State": "",
        "City": "",
        "Country": "ä¸­å›½",
        "PostalCode": find_val_by_key(db_df, ["é‚®æ”¿ç¼–ç "]) or get_db_val(10, 4)
    })
    
    org["Address"].update({
        "State": state, 
        "City": city, 
        "Country": country, 
        "Street1": street,
        "PostalCode": find_val_by_key(db_df, ["é‚®æ”¿ç¼–ç "]) or get_db_val(10, 4)
    })

    # C. é¡¾å®¢ä¸ CSR 
    ensure_path(final_json, ["CustomerInformation"])
    if "Customers" not in final_json["CustomerInformation"] or not isinstance(final_json["CustomerInformation"]["Customers"], list) or not final_json["CustomerInformation"]["Customers"]:
        final_json["CustomerInformation"]["Customers"] = [{}]
        
    cust = final_json["CustomerInformation"]["Customers"][0]
    if "Id" not in cust: cust["Id"] = str(uuid.uuid4())
    if customer_name: cust["Name"] = customer_name
    if supplier_code: cust["SupplierCode"] = supplier_code
    
    if "Csrs" not in cust or not isinstance(cust["Csrs"], list) or not cust["Csrs"]:
        cust["Csrs"] = [{}]
        
    csr = cust["Csrs"][0]
    if customer_name: csr["Name"] = customer_name
    if supplier_code: csr["SupplierCode"] = supplier_code
    if csr_name: csr["NameCSRDocument"] = csr_name
    if csr_date: csr["DateCSRDocument"] = csr_date

    # D. æ–‡ä»¶æ¸…å•å®šç‚¹æ›¿æ¢
    docs_list = []
    if not doc_list_df.empty:
        for c in range(doc_list_df.shape[1]):
            for r in range(doc_list_df.shape[0]):
                cell_val = str(doc_list_df.iloc[r, c]).strip()
                if "å…¬å¸å†…å¯¹åº”çš„ç¨‹åºæ–‡ä»¶" in cell_val or "åŒ…å«åç§°ã€ç¼–å·ã€ç‰ˆæœ¬" in cell_val:
                    for r2 in range(r + 1, doc_list_df.shape[0]):
                        val = str(doc_list_df.iloc[r2, c]).strip()
                        if val and val.lower() != 'nan':
                            docs_list.append(val)
                    break
            if docs_list: break

    if docs_list:
        ensure_path(final_json, ["Stage1DocumentedRequirements"])
        if "IatfClauseDocuments" not in final_json["Stage1DocumentedRequirements"] or not isinstance(final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"], list):
            final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"] = []
            
        clause_docs = final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"]
        for i, doc_name in enumerate(docs_list):
            if i < len(clause_docs):
                if isinstance(clause_docs[i], dict):
                    clause_docs[i]["DocumentName"] = doc_name
            else:
                clause_docs.append({"DocumentName": doc_name})

    # E. è¿‡ç¨‹æ¸…å•é‡å»º
    processes = []
    if not proc_df.empty:
        clause_cols = proc_df.columns[13:] if proc_df.shape[1] > 13 else []
        for idx, row in proc_df.iterrows():
            p_name = str(row.iloc[0]).strip()
            rep_name = str(row.iloc[2]).strip() if pd.notna(row.iloc[2]) else ""
            
            if not p_name or p_name.lower() == 'nan': continue
            proc_obj = {
                "Id": str(uuid.uuid4()),
                "ProcessName": p_name,
                "RepresentativeName": rep_name,
                "ManufacturingProcess": "0",
                "OnSiteProcess": "1",
                "RemoteProcess": "0",
                "AuditNotes": [{
                    "Id": str(uuid.uuid4()),
                    "AuditorId": auditor_id
                }]
            }
            for col in clause_cols:
                if str(row[col]).strip().upper() in ['X', 'TRUE']: proc_obj[col] = True
            processes.append(proc_obj)
    final_json["Processes"] = processes

    # F. ç»“æœæ—¥æœŸ
    if "Results" not in final_json: final_json["Results"] = {}
    if "AuditReportFinal" not in final_json["Results"]: final_json["Results"]["AuditReportFinal"] = {}
    
    if end_iso: final_json["Results"]["AuditReportFinal"]["Date"] = end_iso
    if next_audit_iso: final_json["Results"]["DateNextScheduledAudit"] = next_audit_iso

    return final_json

# ================= ä¸»ç•Œé¢ =================
st.title("ğŸ›¡ï¸ å¤šæ¨¡æ¿å®¡è®¡è½¬æ¢å¼•æ“ (v44.0 åœ°å€é˜²çŸ­è·¯ç‰ˆ)")
st.markdown("ğŸ’¡ **ä¿®å¤æ—¥å¿—**ï¼šå»é™¤äº†å¯¼è‡´è‹±æ–‡åœ°å€è¯»å–æå‰çŸ­è·¯ä¸­æ–­çš„ BUG ä»£ç ï¼Œç°åœ¨è‹±æ–‡ Address èŠ‚ç‚¹å°†å®Œç¾ç”Ÿæˆã€‚")

uploaded_files = st.file_uploader("ğŸ“¥ ä¸Šä¼  Excel æ•°æ®è¡¨", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    st.divider()
    for file in uploaded_files:
        try:
            res_json = generate_json_logic(file, base_template, user_template_data)
            st.success(f"âœ… {file.name} è½¬æ¢æˆåŠŸ")
            
            with st.expander("ğŸ‘€ æŸ¥çœ‹è¯Šæ–­é¢æ¿", expanded=True):
                 st.code(f"""
ã€è‹±æ–‡ Address å®Œç¾åˆ‡åˆ†ç¡®è®¤ã€‘
Street1: "{safe_get(res_json['OrganizationInformation']['Address'], 'Street1')}"
City:    "{safe_get(res_json['OrganizationInformation']['Address'], 'City')}"
State:   "{safe_get(res_json['OrganizationInformation']['Address'], 'State')}"
Country: "{safe_get(res_json['OrganizationInformation']['Address'], 'Country')}"
                 """.strip(), language="yaml")

            st.download_button(
                label=f"ğŸ“¥ ä¸‹è½½ JSON ({file.name})",
                data=json.dumps(res_json, indent=2, ensure_ascii=False),
                file_name=file.name.replace(".xlsx", ".json"),
                key=f"dl_{file.name}"
            )
        except Exception as e:
            st.error(f"âŒ {file.name} æ ¸å¿ƒå¤„ç†å¤±è´¥: {str(e)}")








