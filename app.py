import streamlit as st
import pandas as pd
import json
import uuid
import time
import re
import copy
from datetime import datetime, timedelta

# =====================================================================
# é¡µé¢é…ç½®
# =====================================================================
st.set_page_config(
    page_title="IATF å®¡è®¡è½¬æ¢å·¥å…· (v67.0 åŸç”Ÿ UI ç‰ˆ)",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# =====================================================================
# ä¾§è¾¹æ ï¼šæ¨¡æ¿ä¸æ¨¡å¼é…ç½®
# =====================================================================
with st.sidebar:
    st.header("âš™ï¸ å…¨å±€é…ç½®")
    st.divider()
    
    st.markdown("### ğŸ” æå–æ¨¡å¼é€‰æ‹©")
    run_mode = st.radio(
        "è¯·æ ¹æ®æŠ¥å‘Šç±»å‹é€‰æ‹©ï¼š",
        (
            "çº¯å‡€æ ‡å‡†æ¨¡å¼ (æ— é™„å±åœºæ‰€)", 
            "å•æå–ï¼šEMS æ‰©å±•åœºæ‰€ (F21-M25)", 
            "å•æå–ï¼šRL æ”¯æŒåœºæ‰€ (F27-N32)",
            "å…¨é‡ç»¼åˆæ¨¡å¼ (æå– EMS + RL + è¢«æ”¯æŒåœºæ‰€)"
        ),
        index=0
    )
    st.divider()
    
    st.info("ğŸ’¡ è¯·ä¸Šä¼ æ‚¨çš„ JSON æ¨¡æ¿ã€‚ç¨‹åºå°†æŠŠè¯¥æ–‡ä»¶ä½œä¸ºå®Œæ•´çš„åº•å±‚éª¨æ¶ã€‚")
    user_template_file = st.file_uploader("ä¸Šä¼ åŸºç¡€ JSON æ¨¡æ¿", type=["json"])
    
    base_template_data = None
    if user_template_file:
        try:
            base_template_data = json.load(user_template_file)
            st.success(f"âœ… å·²åŠ è½½åº•åº§: {user_template_file.name}")
        except Exception as e:
            st.error(f"âŒ è§£æå¤±è´¥: {e}")
            st.stop()
    else:
        st.warning("ğŸ‘ˆ è¯·å…ˆä¸Šä¼ åº•åº§æ–‡ä»¶ä»¥å¯åŠ¨ç¨‹åºã€‚")
        st.stop()

# =====================================================================
# é€šç”¨è¾…åŠ©å‡½æ•°åŒº
# =====================================================================
def ensure_path(d, path):
    current = d
    for key in path:
        if key not in current or not isinstance(current[key], dict):
            current[key] = {}
        current = current[key]
    return current

def safe_get(obj, key, default=""):
    if isinstance(obj, dict):
        return obj.get(key, default)
    return default

def extract_and_format_english_name(raw_val):
    clean_val = str(raw_val).replace("å§“å:", "").replace("Name:", "").strip()
    if not clean_val: return ""
    eng_only = re.sub(r'[^a-zA-Z\s]', ' ', clean_val).strip()
    eng_only = re.sub(r'\s+', ' ', eng_only)
    if eng_only:
        parts = eng_only.split()
        if len(parts) >= 2 and parts[0].isupper() and not parts[1].isupper():
            return f"{parts[1]} {parts[0]}"
        else:
            return eng_only
    return clean_val

# =====================================================================
# ç‹¬ç«‹æ¨¡å— 1ï¼šEMS æ‰©å±•åœºæ‰€æå–å™¨ (F21:M25)
# =====================================================================
def extract_ems_sites(info_df):
    ems_sites = []
    if info_df.empty: return ems_sites
    header_r = -1
    col_map = {}
    row_start, row_end = 20, min(25, info_df.shape[0])
    col_start, col_end = 5, min(13, info_df.shape[1])

    for r in range(row_start, row_end):
        for c in range(col_start, col_end):
            val = str(info_df.iloc[r, c]).strip().upper()
            if "EMSæ‰©å±•åœºæ‰€ä¿¡æ¯" in val or "æ‰©å±•åˆ¶é€ åœºæ‰€" in val or "æ‰©å±•ç°åœº" in val:
                header_r = r
                for c_scan in range(col_start, col_end):
                    h_val = str(info_df.iloc[r, c_scan]).strip()
                    if "ä¸­æ–‡åç§°" in h_val: col_map['name_cn'] = c_scan
                    elif "è‹±æ–‡åç§°" in h_val: col_map['name_en'] = c_scan
                    elif "ä¸­æ–‡åœ°å€" in h_val: col_map['addr_cn'] = c_scan
                    elif "è‹±æ–‡åœ°å€" in h_val: col_map['addr_en'] = c_scan
                    elif "é‚®ç¼–" in h_val or "é‚®æ”¿ç¼–ç " in h_val: col_map['zip'] = c_scan
                    elif "USI" in h_val.upper(): col_map['usi'] = c_scan
                    elif "äººæ•°" in h_val: col_map['emp'] = c_scan
                break
        if header_r != -1: break
            
    if header_r != -1:
        for r in range(header_r + 1, row_end):
            def safe_get_cell(row, col_idx):
                if col_idx == -1 or col_idx >= info_df.shape[1]: return ""
                v = str(info_df.iloc[row, col_idx]).strip()
                return "" if v.lower() == 'nan' else v

            name_cn = safe_get_cell(r, col_map.get('name_cn', -1))
            name_en = safe_get_cell(r, col_map.get('name_en', -1))
            addr_cn = safe_get_cell(r, col_map.get('addr_cn', -1))
            
            if not name_cn and not addr_cn: continue
            if "åç§°" in name_cn and "åœ°å€" in addr_cn: continue
            
            full_site_name = name_cn
            if name_en and name_en not in name_cn:
                full_site_name = f"{name_cn} {name_en}".strip()

            addr_en = safe_get_cell(r, col_map.get('addr_en', -1))
            zip_code = safe_get_cell(r, col_map.get('zip', -1))
            usi = safe_get_cell(r, col_map.get('usi', -1))
            emp = safe_get_cell(r, col_map.get('emp', -1))

            ems_street, ems_city, ems_state, ems_country = addr_en, "", "", ""
            if addr_en:
                clean_eng = addr_en.replace('ï¼Œ', ',')
                parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
                if len(parts) >= 3:
                    ems_country = parts[-1]
                    ems_state = parts[-2]
                    ems_city = parts[-3]
                    ems_street = ", ".join(parts[:-3])
                else:
                    ems_street = addr_en

            site_obj = {
                "Id": str(uuid.uuid4()),
                "SiteName": full_site_name,
                "IATF_USI": usi,
                "TotalNumberEmployees": emp,
                "AddressNative": {"Street1": addr_cn, "City": "", "State": "", "Country": "ä¸­å›½", "PostalCode": zip_code},
                "Address": {"Street1": ems_street, "City": ems_city, "State": ems_state, "Country": ems_country, "PostalCode": zip_code}
            }
            ems_sites.append(site_obj)
    return ems_sites

# =====================================================================
# ç‹¬ç«‹æ¨¡å— 2ï¼šRL æ”¯æŒåœºæ‰€æå–å™¨ (F27:N32)
# =====================================================================
def extract_rl_sites(info_df):
    support_sites = []
    if info_df.empty: return support_sites
    header_r = -1
    col_map = {}
    rl_row_start, rl_row_end = 26, min(32, info_df.shape[0])
    rl_col_start, rl_col_end = 5, min(14, info_df.shape[1])

    for r in range(rl_row_start, rl_row_end):
        for c in range(rl_col_start, rl_col_end):
            val = str(info_df.iloc[r, c]).strip().upper()
            if "è¢«æ”¯æŒåœºæ‰€ä¿¡æ¯" in val or "RLæ”¯æŒåœºæ‰€" in val or "æ”¯æŒåœºæ‰€ä¿¡æ¯" in val:
                header_r = r
                for c_scan in range(rl_col_start, rl_col_end):
                    h_val = str(info_df.iloc[r, c_scan]).strip()
                    if "ä¸­æ–‡åç§°" in h_val: col_map['name_cn'] = c_scan
                    elif "è‹±æ–‡åç§°" in h_val: col_map['name_en'] = c_scan
                    elif "ä¸­æ–‡åœ°å€" in h_val: col_map['addr_cn'] = c_scan
                    elif "è‹±æ–‡åœ°å€" in h_val: col_map['addr_en'] = c_scan
                    elif "é‚®ç¼–" in h_val or "é‚®æ”¿ç¼–ç " in h_val: col_map['zip'] = c_scan
                    elif "USI" in h_val.upper(): col_map['usi'] = c_scan
                    elif "äººæ•°" in h_val: col_map['emp'] = c_scan
                    elif "æ”¯æŒåŠŸèƒ½" in h_val: col_map['func'] = c_scan
                break
        if header_r != -1: break
            
    if header_r != -1:
        for r in range(header_r + 1, rl_row_end):
            def safe_get_cell(row, col_idx):
                if col_idx == -1 or col_idx >= info_df.shape[1]: return ""
                v = str(info_df.iloc[row, col_idx]).strip()
                return "" if v.lower() == 'nan' else v

            name_cn = safe_get_cell(r, col_map.get('name_cn', -1))
            name_en = safe_get_cell(r, col_map.get('name_en', -1))
            addr_cn = safe_get_cell(r, col_map.get('addr_cn', -1))
            
            if not name_cn and not addr_cn: continue
            if "åç§°" in name_cn and "åœ°å€" in addr_cn: continue
            
            full_site_name = name_cn
            if name_en and name_en not in name_cn:
                full_site_name = f"{name_cn} {name_en}".strip()

            addr_en = safe_get_cell(r, col_map.get('addr_en', -1))
            zip_code = safe_get_cell(r, col_map.get('zip', -1))
            usi = safe_get_cell(r, col_map.get('usi', -1))
            emp = safe_get_cell(r, col_map.get('emp', -1))
            func = safe_get_cell(r, col_map.get('func', -1))

            rl_street, rl_city, rl_state, rl_country = addr_en, "", "", ""
            if addr_en:
                clean_eng = addr_en.replace('ï¼Œ', ',')
                parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
                if len(parts) >= 3:
                    rl_country = parts[-1]
                    rl_state = parts[-2]
                    rl_city = parts[-3]
                    rl_street = ", ".join(parts[:-3])
                else:
                    rl_street = addr_en

            site_obj = {
                "Id": str(uuid.uuid4()),
                "SiteName": full_site_name,
                "Comments": func,
                "IATF_USI": usi,
                "TotalNumberEmployees": emp,
                "AddressNative": {"Street1": addr_cn, "City": "", "State": "", "Country": "ä¸­å›½", "PostalCode": zip_code},
                "Address": {"Street1": rl_street, "City": rl_city, "State": rl_state, "Country": rl_country, "PostalCode": zip_code}
            }
            support_sites.append(site_obj)
    return support_sites

# =====================================================================
# ç‹¬ç«‹æ¨¡å— 3ï¼šè¢«æ”¯æŒåœºæ‰€æå–å™¨ (F34:N38)
# =====================================================================
def extract_receiving_sites(info_df):
    receiving_sites = []
    if info_df.empty: return receiving_sites
    header_r = -1
    col_map = {}
    
    rec_row_start, rec_row_end = 33, min(38, info_df.shape[0])
    rec_col_start, rec_col_end = 5, min(14, info_df.shape[1])

    for r in range(rec_row_start, rec_row_end):
        for c in range(rec_col_start, rec_col_end):
            val = str(info_df.iloc[r, c]).strip().upper()
            if "è¢«æ”¯æŒåœºæ‰€ä¿¡æ¯" in val or "è¢«æ”¯æŒåœºæ‰€" in val:
                header_r = r
                for c_scan in range(rec_col_start, rec_col_end):
                    h_val = str(info_df.iloc[r, c_scan]).strip()
                    if "ä¸­æ–‡åç§°" in h_val: col_map['name_cn'] = c_scan
                    elif "è‹±æ–‡åç§°" in h_val: col_map['name_en'] = c_scan
                    elif "ä¸­æ–‡åœ°å€" in h_val: col_map['addr_cn'] = c_scan
                    elif "è‹±æ–‡åœ°å€" in h_val: col_map['addr_en'] = c_scan
                    elif "é‚®ç¼–" in h_val or "é‚®æ”¿ç¼–ç " in h_val: col_map['zip'] = c_scan
                    elif "USI" in h_val.upper(): col_map['usi'] = c_scan
                    elif "äººæ•°" in h_val: col_map['emp'] = c_scan
                    elif "æ”¯æŒåŠŸèƒ½" in h_val: col_map['func'] = c_scan
                break
        if header_r != -1: break
            
    if header_r != -1:
        for r in range(header_r + 1, rec_row_end):
            def safe_get_cell(row, col_idx):
                if col_idx == -1 or col_idx >= info_df.shape[1]: return ""
                v = str(info_df.iloc[row, col_idx]).strip()
                return "" if v.lower() == 'nan' else v

            name_cn = safe_get_cell(r, col_map.get('name_cn', -1))
            name_en = safe_get_cell(r, col_map.get('name_en', -1))
            addr_cn = safe_get_cell(r, col_map.get('addr_cn', -1))
            
            if not name_cn and not addr_cn: continue
            if "åç§°" in name_cn and "åœ°å€" in addr_cn: continue
            
            full_site_name = name_cn
            if name_en and name_en not in name_cn:
                full_site_name = f"{name_cn} {name_en}".strip()

            addr_en = safe_get_cell(r, col_map.get('addr_en', -1))
            zip_code = safe_get_cell(r, col_map.get('zip', -1))
            usi = safe_get_cell(r, col_map.get('usi', -1))
            emp = safe_get_cell(r, col_map.get('emp', -1))
            func = safe_get_cell(r, col_map.get('func', -1))

            rec_street, rec_city, rec_state, rec_country = addr_en, "", "", ""
            if addr_en:
                clean_eng = addr_en.replace('ï¼Œ', ',')
                parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
                if len(parts) >= 3:
                    rec_country = parts[-1]
                    rec_state = parts[-2]
                    rec_city = parts[-3]
                    rec_street = ", ".join(parts[:-3])
                else:
                    rec_street = addr_en

            site_obj = {
                "Id": str(uuid.uuid4()),
                "SiteName": full_site_name,
                "Comments": func,
                "IATF_USI": usi,
                "TotalNumberEmployees": emp,
                "AddressNative": {"Street1": addr_cn, "City": "", "State": "", "Country": "ä¸­å›½", "PostalCode": zip_code},
                "Address": {"Street1": rec_street, "City": rec_city, "State": rec_state, "Country": rec_country, "PostalCode": zip_code}
            }
            receiving_sites.append(site_obj)
    return receiving_sites

# =====================================================================
# ä¸»æµç¨‹åŒºï¼šæ ¸å¿ƒè½¬æ¢é€»è¾‘
# =====================================================================
def generate_json_logic(excel_file, base_data, mode):
    final_json = copy.deepcopy(base_data)
    
    try:
        xls = pd.ExcelFile(excel_file)
        db_df = pd.read_excel(xls, sheet_name='æ•°æ®åº“', header=None) if 'æ•°æ®åº“' in xls.sheet_names else pd.read_excel(xls, sheet_name=0, header=None)
        proc_df = pd.read_excel(xls, sheet_name='è¿‡ç¨‹æ¸…å•') if 'è¿‡ç¨‹æ¸…å•' in xls.sheet_names else pd.DataFrame()
        info_df = pd.read_excel(xls, sheet_name='ä¿¡æ¯', header=None) if 'ä¿¡æ¯' in xls.sheet_names else pd.DataFrame()
        doc_list_df = pd.read_excel(xls, sheet_name=xls.sheet_names[8], header=None) if len(xls.sheet_names) >= 9 else pd.DataFrame()
    except Exception as e:
        raise ValueError(f"Excel è¯»å–å¤±è´¥: {str(e)}")

    def find_val_by_key(df, keywords, col_offset=1):
        if df.empty: return ""
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                cell_val = str(df.iloc[r, c]).strip()
                for k in keywords:
                    if k in cell_val:
                        if c + col_offset < df.shape[1]:
                            return str(df.iloc[r, c + col_offset]).strip()
        return ""
        
    def get_db_val(r, c):
        try:
            val = db_df.iloc[r, c]
            return str(val).strip() if pd.notna(val) else ""
        except: return ""

    raw_name_full = find_val_by_key(db_df, ["å§“å", "Auditor Name"]) or get_db_val(5, 1)
    raw_name = raw_name_full.replace("å§“å:", "").replace("Name:", "").strip() if raw_name_full else ""
    formatted_team_name = extract_and_format_english_name(raw_name_full)

    ccaa_raw = find_val_by_key(db_df, ["å®¡æ ¸å‘˜CCAA", "CCAA"]) or get_db_val(4, 1)
    caa_no = ""
    if ccaa_raw:
        match = re.search(r'(?:CCAA[:ï¼š\s-])\s*(.*)', ccaa_raw, re.IGNORECASE | re.DOTALL)
        caa_no = match.group(1).strip() if match else ccaa_raw.strip()

    auditor_id = ""
    if not info_df.empty:
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                cell_text = str(info_df.iloc[r, c])
                if "IATF Card" in cell_text or "IATFå¡å·" in cell_text:
                    if c + 1 < info_df.shape[1]:
                        raw_val = str(info_df.iloc[r, c + 1]).strip()
                        raw_val = raw_val.replace('\n', ' ').replace('\r', ' ')
                        auditor_id = re.sub(r'^IATF[:ï¼š\s-]*', '', raw_val, flags=re.IGNORECASE).strip()
                        if len(auditor_id) > 4: break
            if auditor_id and len(auditor_id) > 4: break

    start_date_raw = find_val_by_key(db_df, ["å®¡æ ¸å¼€å§‹æ—¥æœŸ", "å®¡æ ¸å¼€å§‹æ—¶é—´"]) or get_db_val(2, 1)
    end_date_raw = find_val_by_key(db_df, ["å®¡æ ¸ç»“æŸæ—¥æœŸ", "å®¡æ ¸ç»“æŸæ—¶é—´"]) or get_db_val(3, 1)
    
    def fmt_iso(val):
        try:
            clean_val = str(val).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
            dt = pd.to_datetime(clean_val, errors='coerce')
            if pd.notna(dt): return dt.strftime('%Y-%m-%d') + "T00:00:00.000Z"
        except: pass
        return ""
        
    start_iso, end_iso = fmt_iso(start_date_raw), fmt_iso(end_date_raw)
    
    next_audit_iso = ""
    try:
        clean_end = str(end_date_raw).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
        end_dt = pd.to_datetime(clean_end, errors='coerce')
        if pd.notna(end_dt): next_audit_iso = (end_dt + timedelta(days=45)).strftime('%Y-%m-%d') + "T00:00:00.000Z"
    except: pass

    customers_list = []
    if not info_df.empty:
        header_r = -1
        col_map = {'cust': -1, 'name': -1, 'date': -1, 'code': -1}
        for r in range(info_df.shape[0]):
            row_str = " ".join([str(x) for x in info_df.iloc[r, :]]).upper()
            if "CUSTOMER" in row_str and ("CSR" in row_str or "TITLE" in row_str):
                header_r = r
                for c in range(info_df.shape[1]):
                    val = str(info_df.iloc[r, c]).strip().upper()
                    if "CUSTOMER" in val or "å®¢æˆ·" in val: col_map['cust'] = c
                    elif "CSR" in val or "TITLE" in val: col_map['name'] = c
                    elif "VERSION" in val or "DATE" in val or "ç‰ˆæœ¬" in val or "æ—¥æœŸ" in val: col_map['date'] = c
                    elif "ä¾›åº”å•†ä»£ç " in val or "SUPPLIER" in val or "CODE" in val: col_map['code'] = c
                break
                
        if header_r != -1:
            for r in range(header_r + 1, info_df.shape[0]):
                cust_val = str(info_df.iloc[r, col_map['cust']]).strip() if col_map['cust'] != -1 else ""
                if not cust_val or cust_val.lower() == 'nan': continue
                if "å®¡æ ¸å‘˜" in cust_val or "AUDIT" in cust_val.upper() or "NAME" in cust_val.upper(): break
                    
                name_val = str(info_df.iloc[r, col_map['name']]).strip() if col_map['name'] != -1 else ""
                date_val = str(info_df.iloc[r, col_map['date']]).strip() if col_map['date'] != -1 else ""
                code_val = str(info_df.iloc[r, col_map['code']]).strip() if col_map['code'] != -1 else ""
                
                final_date = date_val.replace(" 00:00:00", "").strip()
                customers_list.append({
                    "Name": cust_val, "SupplierCode": code_val, "NameCSRDocument": name_val, "DateCSRDocument": final_date
                })

    if not customers_list:
        customer_name = find_val_by_key(db_df, ["é¡¾å®¢", "å®¢æˆ·åç§°"]) or get_db_val(29, 1)
        supplier_code = find_val_by_key(db_df, ["ä¾›åº”å•†ç¼–ç ", "ä¾›åº”å•†ä»£ç "]) or get_db_val(30, 1)
        csr_name = find_val_by_key(db_df, ["CSRæ–‡ä»¶åç§°"]) or get_db_val(31, 1)
        csr_date_raw = find_val_by_key(db_df, ["CSRæ–‡ä»¶æ—¥æœŸ"]) or get_db_val(32, 1)
        csr_date = str(csr_date_raw).replace(" 00:00:00", "").strip()
        if csr_date.lower() == 'nan': csr_date = ""
        if customer_name or supplier_code or csr_name:
            customers_list.append({
                "Name": customer_name, "SupplierCode": supplier_code, "NameCSRDocument": csr_name, "DateCSRDocument": csr_date
            })

    # ä¸»åœ°å€æ··åˆå‰¥ç¦»æ‰«æ
    english_address = ""
    native_street = ""
    cands = []
    if not db_df.empty:
        for r_idx in range(9, 14):
            if r_idx < db_df.shape[0]:
                if 1 < db_df.shape[1]: cands.append(str(db_df.iloc[r_idx, 1]))
                if 4 < db_df.shape[1]: cands.append(str(db_df.iloc[r_idx, 4]))
                
    def get_anchored(df, keywords):
        res = []
        if df.empty: return res
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                val = str(df.iloc[r, c]).strip().upper()
                if any(k in val for k in keywords):
                    res.append(str(df.iloc[r, c])) 
                    if c + 1 < df.shape[1]: res.append(str(df.iloc[r, c+1]))
                    if c + 2 < df.shape[1]: res.append(str(df.iloc[r, c+2]))
                    if r + 1 < df.shape[0]: res.append(str(df.iloc[r+1, c]))
                    if r + 1 < df.shape[0] and c+1 < df.shape[1]: res.append(str(df.iloc[r+1, c+1]))
        return res
        
    cands += get_anchored(info_df, ["å®¡æ ¸åœ°å€", "AUDIT ADDRESS", "ADDRESS"])
    cands += get_anchored(db_df, ["åœ°å€", "ADDRESS"])
    
    en_parts, zh_parts = [], []
    for cand in cands:
        cand = str(cand).strip()
        if not cand or cand.lower() == 'nan': continue
        cand = re.sub(r'^(å®¡æ ¸åœ°å€|ç»„ç»‡åœ°å€|ä¼ä¸šåœ°å€|åœ°å€|ç°åœºåœ°å€|AUDIT ADDRESS|ADDRESS)[\s:ï¼š]*', '', cand, flags=re.IGNORECASE).strip()
        if not cand: continue
        
        lines = cand.replace('\r', '\n').split('\n')
        for line in lines:
            line = line.strip()
            if not line: continue
            
            has_zh = bool(re.search(r'[\u4e00-\u9fff]', line))
            has_en = bool(re.search(r'[a-zA-Z]{3,}', line)) 
            
            if has_zh and has_en:
                en_str = re.sub(r'[\u4e00-\u9fff]', ' ', line)
                en_str = re.sub(r'[ï¼Œã€‚ï¼›ï¼ˆï¼‰]', ' ', en_str) 
                en_str = re.sub(r'\s+', ' ', en_str).strip(" ()-.,")
                zh_str = re.sub(r'[a-zA-Z]', '', line)
                zh_str = re.sub(r'\s+', ' ', zh_str).strip(" ()-.,")
                
                if len(en_str) > 10: en_parts.append(en_str)
                if len(zh_str) > 5: zh_parts.append(zh_str)
            elif has_zh: zh_parts.append(line)
            elif has_en: en_parts.append(line)

    english_address = max(en_parts, key=len) if en_parts else ""
    native_street = max(zh_parts, key=len) if zh_parts else ""

    street, city, state, country = english_address, "", "", ""
    if english_address:
        clean_eng = english_address.replace('ï¼Œ', ',')
        parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
        if len(parts) >= 3:
            country = parts[-1]
            state = parts[-2]
            city = parts[-3]
            street = ", ".join(parts[:-3])
        else:
            street = english_address

    final_json["uuid"] = str(uuid.uuid4())
    final_json["created"] = int(time.time() * 1000)

    ensure_path(final_json, ["AuditData", "AuditDate"])
    if start_iso: final_json["AuditData"]["AuditDate"]["Start"] = start_iso
    if end_iso: final_json["AuditData"]["AuditDate"]["End"] = end_iso
    final_json["AuditData"]["CbIdentificationNo"] = find_val_by_key(db_df, ["è®¤è¯æœºæ„æ ‡è¯†å·"]) or get_db_val(2, 4)
    final_json["AuditData"]["AuditorName"] = raw_name
    final_json["AuditData"]["auditorname"] = raw_name

    if "AuditTeam" not in final_json["AuditData"] or not isinstance(final_json["AuditData"]["AuditTeam"], list) or len(final_json["AuditData"]["AuditTeam"]) == 0:
        final_json["AuditData"]["AuditTeam"] = [{}]
        
    team = final_json["AuditData"]["AuditTeam"][0]
    if isinstance(team, dict):
        team.update({
            "Name": formatted_team_name, "CaaNo": caa_no, "AuditorId": auditor_id, 
            "AuditDaysPerformed": 1.5, "DatesOnSite": [{"Date": start_iso, "Day": 1}, {"Date": end_iso, "Day": 0.5}]
        })

    ensure_path(final_json, ["OrganizationInformation", "AddressNative"])
    ensure_path(final_json, ["OrganizationInformation", "Address"])
    org = final_json["OrganizationInformation"]
    
    org["OrganizationName"] = find_val_by_key(db_df, ["ç»„ç»‡åç§°"]) or get_db_val(1, 4)
    org["IndustryCode"] = find_val_by_key(db_df, ["è¡Œä¸šä»£ç ", "Industry Code"])
    org["IATF_USI"] = find_val_by_key(db_df, ["IATF USI", "USI"]) or get_db_val(3, 4)
    org["TotalNumberEmployees"] = find_val_by_key(db_df, ["åŒ…æ‹¬æ‰©å±•ç°åœºåœ¨å†…çš„å‘˜å·¥æ€»æ•°", "å‘˜å·¥æ€»æ•°"]) or get_db_val(27, 1)
    org["CertificateScope"] = find_val_by_key(db_df, ["è¯ä¹¦èŒƒå›´"])
    org["Representative"] = find_val_by_key(db_df, ["ç»„ç»‡ä»£è¡¨", "ç®¡ç†è€…ä»£è¡¨", "è”ç³»äºº", "Representative"]) or get_db_val(15, 1)
    org["Telephone"] = find_val_by_key(db_df, ["è”ç³»ç”µè¯", "ç”µè¯", "Telephone"]) or get_db_val(15, 4)
    extracted_email = find_val_by_key(db_df, ["ç”µå­é‚®ç®±", "é‚®ç®±", "Email", "E-mail"]) or get_db_val(16, 1)
    org["Email"] = "" if str(extracted_email).strip() == "0" else extracted_email
    
    if "LanguageByManufacturingPersonnel" in org:
        lang_node = org["LanguageByManufacturingPersonnel"]
        if isinstance(lang_node, list) and len(lang_node) > 0:
            if isinstance(lang_node[0], dict): lang_node[0]["Products"] = ""
        elif isinstance(lang_node, dict):
            if "0" in lang_node and isinstance(lang_node["0"], dict): lang_node["0"]["Products"] = ""
            else: lang_node["Products"] = ""
    
    if native_street:
        org["AddressNative"]["Street1"] = native_street
    org["AddressNative"]["Country"] = "ä¸­å›½"
    
    if english_address:
        org["Address"]["State"] = state
        org["Address"]["City"] = city
        org["Address"]["Country"] = country if country else "China"
        org["Address"]["Street1"] = street
        
    postal_code = find_val_by_key(db_df, ["é‚®æ”¿ç¼–ç "]) or get_db_val(10, 4)
    if postal_code:
        org["AddressNative"]["PostalCode"] = postal_code
        org["Address"]["PostalCode"] = postal_code

    # =====================================================================
    # ğŸ’¥ æ ¸å¿ƒæ§åˆ¶åˆ†æ”¯ï¼šæ ¹æ®æ¨¡å¼æ‹”æ’æ¨¡å—
    # =====================================================================
    if "å…¨é‡ç»¼åˆæ¨¡å¼" in mode:
        ems_sites = extract_ems_sites(info_df)
        if ems_sites:
            final_json["ExtendedManufacturingSites"] = ems_sites
            org["ExtendedManufacturingSite"] = "1"
        else:
            org["ExtendedManufacturingSite"] = "0"
            
        support_sites = extract_rl_sites(info_df)
        if support_sites:
            final_json["ProvidingSupportSites"] = support_sites
            
        receiving_sites = extract_receiving_sites(info_df)
        if receiving_sites:
            final_json["ReceivingSupportSites"] = receiving_sites
            
    elif "EMS" in mode:
        ems_sites = extract_ems_sites(info_df)
        if ems_sites:
            final_json["ExtendedManufacturingSites"] = ems_sites
            org["ExtendedManufacturingSite"] = "1"
        else:
            org["ExtendedManufacturingSite"] = "0"
            
    elif "RL" in mode:
        org["ExtendedManufacturingSite"] = "0"
        support_sites = extract_rl_sites(info_df)
        if support_sites:
            final_json["ProvidingSupportSites"] = support_sites
            
    else:
        org["ExtendedManufacturingSite"] = "0"

    ensure_path(final_json, ["CustomerInformation"])
    final_json["CustomerInformation"]["Customers"] = []
    for c_info in customers_list:
        cust_obj = {
            "Id": str(uuid.uuid4()), "Name": c_info["Name"], "SupplierCode": c_info["SupplierCode"],
            "Csrs": [{"Id": str(uuid.uuid4()), "Name": c_info["Name"], "SupplierCode": c_info["SupplierCode"],
                      "NameCSRDocument": c_info["NameCSRDocument"], "DateCSRDocument": c_info["DateCSRDocument"]}]
        }
        final_json["CustomerInformation"]["Customers"].append(cust_obj)

    docs_list = []
    if not doc_list_df.empty:
        for c in range(doc_list_df.shape[1]):
            for r in range(doc_list_df.shape[0]):
                cell_val = str(doc_list_df.iloc[r, c]).strip()
                if "å…¬å¸å†…å¯¹åº”çš„ç¨‹åºæ–‡ä»¶" in cell_val or "åŒ…å«åç§°ã€ç¼–å·ã€ç‰ˆæœ¬" in cell_val:
                    for r2 in range(r + 1, doc_list_df.shape[0]):
                        val = str(doc_list_df.iloc[r2, c]).strip()
                        if val and val.lower() != 'nan': docs_list.append(val)
                    break
            if docs_list: break

    if docs_list:
        ensure_path(final_json, ["Stage1DocumentedRequirements"])
        if "IatfClauseDocuments" not in final_json["Stage1DocumentedRequirements"] or not isinstance(final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"], list):
            final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"] = []
        clause_docs = final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"]
        for i, doc_name in enumerate(docs_list):
            if i < len(clause_docs):
                if isinstance(clause_docs[i], dict): clause_docs[i]["DocumentName"] = doc_name
            else:
                clause_docs.append({"DocumentName": doc_name})

    processes = []
    if not proc_df.empty:
        clause_cols = proc_df.columns[13:] if proc_df.shape[1] > 13 else []
        for idx, row in proc_df.iterrows():
            p_name = str(row.iloc[0]).strip()
            rep_name = str(row.iloc[2]).strip() if pd.notna(row.iloc[2]) else ""
            if not p_name or p_name.lower() == 'nan': continue
            proc_obj = {
                "Id": str(uuid.uuid4()), "ProcessName": p_name, "RepresentativeName": rep_name,
                "ManufacturingProcess": "0", "OnSiteProcess": "1", "RemoteProcess": "0",
                "AuditNotes": [{"Id": str(uuid.uuid4()), "AuditorId": auditor_id, "AuditorName": raw_name}]
            }
            for col in clause_cols:
                if str(row[col]).strip().upper() in ['X', 'TRUE']: proc_obj[col] = True
            processes.append(proc_obj)
    final_json["Processes"] = processes

    if "Results" not in final_json: final_json["Results"] = {}
    if "AuditReportFinal" not in final_json["Results"]: final_json["Results"]["AuditReportFinal"] = {}
    if end_iso: final_json["Results"]["AuditReportFinal"]["Date"] = end_iso
    if next_audit_iso: final_json["Results"]["DateNextScheduledAudit"] = next_audit_iso
    
    b6_raw_val = get_db_val(5, 1)
    b6_formatted_name = extract_and_format_english_name(b6_raw_val)
    final_json["Results"]["AuditReportFinal"]["AuditorName"] = b6_formatted_name

    return final_json

# =====================================================================
# ä¸»ç•Œé¢å±•ç¤ºåŒº
# =====================================================================

st.title("ğŸ›¡ï¸ å¤šæ¨¡æ¿å®¡è®¡è½¬æ¢å¼•æ“ (v67.0 åŸç”Ÿ UI æ¢å¤ç‰ˆ)")
st.markdown(f"ğŸ’¡ **å½“å‰è¿è¡Œæ¨¡å¼**: `{run_mode}`")

st.markdown("### ğŸ“¥ ä¸Šä¼ æ•°æ®æº")
uploaded_files = st.file_uploader("æ”¯æŒæ‰¹é‡ä¸Šä¼  .xlsx æ ¼å¼æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    st.divider()
    
    for file in uploaded_files:
        try:
            res_json = generate_json_logic(file, base_template_data, run_mode)
            st.success(f"âœ… è§£ææˆåŠŸï¼š{file.name}")
            
            row_col1, row_col2 = st.columns([3, 1])
            
            with row_col1:
                with st.expander("ğŸ‘€ æŸ¥çœ‹æ•°æ®æå–æ—¥å¿—", expanded=True):
                     if "å…¨é‡ç»¼åˆæ¨¡å¼" in run_mode:
                         ems_count = len(res_json.get('ExtendedManufacturingSites', []))
                         rl_count = len(res_json.get('ProvidingSupportSites', []))
                         rec_count = len(res_json.get('ReceivingSupportSites', []))
                         st.code(f"""
[æ¨¡å—: å…¨é‡ç»¼åˆæå–]
âœ… EMSæ‰©å±•åœºæ‰€æå–: {ems_count} ä¸ª
âœ… RLæ”¯æŒåœºæ‰€æå– : {rl_count} ä¸ª
âœ… è¢«æ”¯æŒåœºæ‰€æå– : {rec_count} ä¸ª
æ ‡å¿—ä½(EMS): "{res_json.get('OrganizationInformation', {}).get('ExtendedManufacturingSite', 'ç¼ºå¤±')}"
                         """.strip(), language="yaml")
                         
                     elif "EMS" in run_mode:
                         try:
                             ems_sites = res_json.get('ExtendedManufacturingSites', [])
                             ems_count = len(ems_sites)
                             ems_sample = ems_sites[0] if ems_count > 0 else {}
                         except:
                             ems_count, ems_sample = 0, {}
                         st.code(f"""
[æ¨¡å—: EMSæ‰©å±•åœºæ‰€]
æå–æ•°é‡: {ems_count} ä¸ª
åœºæ‰€åç§°: "{safe_get(ems_sample, 'SiteName', 'æ— ')}"
æ ‡å¿—ä½: "{res_json.get('OrganizationInformation', {}).get('ExtendedManufacturingSite', 'ç¼ºå¤±')}"
                         """.strip(), language="yaml")
                         
                     elif "RL" in run_mode:
                         try:
                             rl_sites = res_json.get('ProvidingSupportSites', [])
                             rl_count = len(rl_sites)
                             rl_sample = rl_sites[0] if rl_count > 0 else {}
                         except:
                             rl_count, rl_sample = 0, {}
                         st.code(f"""
[æ¨¡å—: RLæ”¯æŒåœºæ‰€]
æå–æ•°é‡: {rl_count} ä¸ª
åœºæ‰€åç§°: "{safe_get(rl_sample, 'SiteName', 'æ— ')}"
                         """.strip(), language="yaml")
                         
                     else:
                         st.code(f"""
[æ¨¡å—: çº¯å‡€æ ‡å‡†]
ä¸­æ–‡ä¸»åœ°å€: "{safe_get(res_json.get('OrganizationInformation', {}).get('AddressNative', {}), 'Street1', 'ç¼ºå¤±')}"
è‹±æ–‡ä¸»åœ°å€: "{safe_get(res_json.get('OrganizationInformation', {}).get('Address', {}), 'Street1', 'ç¼ºå¤±')}"
                         """.strip(), language="yaml")

            with row_col2:
                st.download_button(
                    label=f"ğŸ“¥ ä¸‹è½½ JSON æ–‡ä»¶",
                    data=json.dumps(res_json, indent=2, ensure_ascii=False),
                    file_name=file.name.replace(".xlsx", ".json"),
                    key=f"dl_{file.name}"
                )
        except Exception as e:
            st.error(f"âŒ è§£æ {file.name} å¤±è´¥: {str(e)}")





















