import streamlit as st
import pandas as pd
import json
import uuid
import time
import re
import copy
from datetime import datetime, timedelta

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="IATF å®¡è®¡è½¬æ¢å·¥å…· (v54.2 EMSä¿®å¤ç‰ˆ)",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# --- 1. ä¾§è¾¹æ ï¼šæ¨¡æ¿åŠ è½½ ---
with st.sidebar:
    st.header("âš™ï¸ æ¨¡æ¿é…ç½®")
    
    st.info("ğŸ’¡ è¯·ä¸Šä¼ æ‚¨çš„ JSON æ¨¡æ¿ã€‚ç¨‹åºå°†æŠŠè¯¥æ–‡ä»¶ä½œä¸ºå®Œæ•´çš„åº•å±‚éª¨æ¶ã€‚")
    user_template_file = st.file_uploader("ä¸Šä¼ åŸºç¡€ JSON æ¨¡æ¿", type=["json"])
    
    base_template_data = None
    if user_template_file:
        try:
            base_template_data = json.load(user_template_file)
            st.success(f"âœ… æˆåŠŸåŠ è½½åº•åº§æ¨¡æ¿: {user_template_file.name}")
        except Exception as e:
            st.error(f"âŒ æ¨¡æ¿è§£æå¤±è´¥: {e}")
            st.stop()
    else:
        st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  JSON æ¨¡æ¿æ–‡ä»¶ã€‚")
        st.stop()

# --- è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨å¯»å€ ---
def ensure_path(d, path):
    current = d
    for key in path:
        if key not in current or not isinstance(current[key], dict):
            current[key] = {}
        current = current[key]
    return current

def safe_get(obj, key, default=""):
    if isinstance(obj, dict):
        return obj.get(key, default)
    return default

# --- æ ¸å¿ƒè½¬æ¢é€»è¾‘ ---
def generate_json_logic(excel_file, base_data):
    # ğŸ’¥ ç›´æ¥ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„æ¨¡æ¿ä½œä¸ºæœ€ç»ˆåº•åº§
    final_json = copy.deepcopy(base_data)
    
    try:
        xls = pd.ExcelFile(excel_file)
        db_df = pd.read_excel(xls, sheet_name='æ•°æ®åº“', header=None) if 'æ•°æ®åº“' in xls.sheet_names else pd.read_excel(xls, sheet_name=0, header=None)
        proc_df = pd.read_excel(xls, sheet_name='è¿‡ç¨‹æ¸…å•') if 'è¿‡ç¨‹æ¸…å•' in xls.sheet_names else pd.DataFrame()
        info_df = pd.read_excel(xls, sheet_name='ä¿¡æ¯', header=None) if 'ä¿¡æ¯' in xls.sheet_names else pd.DataFrame()
        doc_list_df = pd.read_excel(xls, sheet_name=xls.sheet_names[8], header=None) if len(xls.sheet_names) >= 9 else pd.DataFrame()
    except Exception as e:
        raise ValueError(f"Excel è¯»å–å¤±è´¥: {str(e)}")

    def find_val_by_key(df, keywords, col_offset=1):
        if df.empty: return ""
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                cell_val = str(df.iloc[r, c]).strip()
                for k in keywords:
                    if k in cell_val:
                        if c + col_offset < df.shape[1]:
                            return str(df.iloc[r, c + col_offset]).strip()
        return ""
        
    def get_db_val(r, c):
        try:
            val = db_df.iloc[r, c]
            return str(val).strip() if pd.notna(val) else ""
        except: return ""

    # ================= 2. æ•°æ®æå– =================
    
    # [è¾…åŠ©å‡½æ•°ï¼šæš´åŠ›å‰¥ç¦»æ‰€æœ‰éè‹±æ–‡å­—æ¯ï¼Œå¹¶é‡æ’å¤§å°å†™]
    def extract_and_format_english_name(raw_val):
        clean_val = str(raw_val).replace("å§“å:", "").replace("Name:", "").strip()
        if not clean_val: return ""
        
        eng_only = re.sub(r'[^a-zA-Z\s]', ' ', clean_val).strip()
        eng_only = re.sub(r'\s+', ' ', eng_only)
        
        if eng_only:
            parts = eng_only.split()
            if len(parts) >= 2 and parts[0].isupper() and not parts[1].isupper():
                return f"{parts[1]} {parts[0]}"
            else:
                return eng_only
        return clean_val

    # [å…¨å±€å§“åï¼šä¿æŒåŸå§‹ä¸­æ–‡ä¸å¤„ç†ï¼Œä¾› AuditData ä½¿ç”¨]
    raw_name_full = find_val_by_key(db_df, ["å§“å", "Auditor Name"]) or get_db_val(5, 1)
    raw_name = raw_name_full.replace("å§“å:", "").replace("Name:", "").strip() if raw_name_full else ""

    # [ç”Ÿæˆæ ¼å¼åŒ–åçš„è‹±æ–‡åï¼Œä¸“é—¨ä¾› AuditTeam çš„ Name ä½¿ç”¨]
    formatted_team_name = extract_and_format_english_name(raw_name_full)

    # [CCAA]
    ccaa_raw = find_val_by_key(db_df, ["å®¡æ ¸å‘˜CCAA", "CCAA"]) or get_db_val(4, 1)
    caa_no = ""
    if ccaa_raw:
        match = re.search(r'(?:CCAA[:ï¼š\s-])\s*(.*)', ccaa_raw, re.IGNORECASE | re.DOTALL)
        caa_no = match.group(1).strip() if match else ccaa_raw.strip()

    # [AuditorId]
    auditor_id = ""
    if not info_df.empty:
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                cell_text = str(info_df.iloc[r, c])
                if "IATF Card" in cell_text or "IATFå¡å·" in cell_text:
                    if c + 1 < info_df.shape[1]:
                        raw_val = str(info_df.iloc[r, c + 1]).strip()
                        raw_val = raw_val.replace('\n', ' ').replace('\r', ' ')
                        auditor_id = re.sub(r'^IATF[:ï¼š\s-]*', '', raw_val, flags=re.IGNORECASE).strip()
                        if len(auditor_id) > 4: break
            if auditor_id and len(auditor_id) > 4: break

    # [æ—¥æœŸ]
    start_date_raw = find_val_by_key(db_df, ["å®¡æ ¸å¼€å§‹æ—¥æœŸ", "å®¡æ ¸å¼€å§‹æ—¶é—´"]) or get_db_val(2, 1)
    end_date_raw = find_val_by_key(db_df, ["å®¡æ ¸ç»“æŸæ—¥æœŸ", "å®¡æ ¸ç»“æŸæ—¶é—´"]) or get_db_val(3, 1)
    
    def fmt_iso(val):
        try:
            clean_val = str(val).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
            dt = pd.to_datetime(clean_val, errors='coerce')
            if pd.notna(dt): return dt.strftime('%Y-%m-%d') + "T00:00:00.000Z"
        except: pass
        return ""
        
    start_iso, end_iso = fmt_iso(start_date_raw), fmt_iso(end_date_raw)
    
    next_audit_iso = ""
    try:
        clean_end = str(end_date_raw).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
        end_dt = pd.to_datetime(clean_end, errors='coerce')
        if pd.notna(end_dt): next_audit_iso = (end_dt + timedelta(days=45)).strftime('%Y-%m-%d') + "T00:00:00.000Z"
    except: pass

    # [å¤šé¡¾å®¢ä¸ CSR åŠ¨æ€æå–]
    customers_list = []
    if not info_df.empty:
        header_r = -1
        col_map = {'cust': -1, 'name': -1, 'date': -1, 'code': -1}
        for r in range(info_df.shape[0]):
            row_str = " ".join([str(x) for x in info_df.iloc[r, :]]).upper()
            if "CUSTOMER" in row_str and ("CSR" in row_str or "TITLE" in row_str):
                header_r = r
                for c in range(info_df.shape[1]):
                    val = str(info_df.iloc[r, c]).strip().upper()
                    if "CUSTOMER" in val or "å®¢æˆ·" in val: col_map['cust'] = c
                    elif "CSR" in val or "TITLE" in val: col_map['name'] = c
                    elif "VERSION" in val or "DATE" in val or "ç‰ˆæœ¬" in val or "æ—¥æœŸ" in val: col_map['date'] = c
                    elif "ä¾›åº”å•†ä»£ç " in val or "SUPPLIER" in val or "CODE" in val: col_map['code'] = c
                break
                
        if header_r != -1:
            for r in range(header_r + 1, info_df.shape[0]):
                cust_val = str(info_df.iloc[r, col_map['cust']]).strip() if col_map['cust'] != -1 else ""
                if not cust_val or cust_val.lower() == 'nan': continue
                if "å®¡æ ¸å‘˜" in cust_val or "AUDIT" in cust_val.upper() or "NAME" in cust_val.upper(): break
                    
                name_val = str(info_df.iloc[r, col_map['name']]).strip() if col_map['name'] != -1 else ""
                date_val = str(info_df.iloc[r, col_map['date']]).strip() if col_map['date'] != -1 else ""
                code_val = str(info_df.iloc[r, col_map['code']]).strip() if col_map['code'] != -1 else ""
                
                if name_val.lower() == 'nan': name_val = ""
                if date_val.lower() == 'nan': date_val = ""
                if code_val.lower() == 'nan': code_val = ""

                final_date = date_val.replace(" 00:00:00", "").strip()

                customers_list.append({
                    "Name": cust_val,
                    "SupplierCode": code_val,
                    "NameCSRDocument": name_val,
                    "DateCSRDocument": final_date
                })

    if not customers_list:
        customer_name = find_val_by_key(db_df, ["é¡¾å®¢", "å®¢æˆ·åç§°"]) or get_db_val(29, 1)
        supplier_code = find_val_by_key(db_df, ["ä¾›åº”å•†ç¼–ç ", "ä¾›åº”å•†ä»£ç "]) or get_db_val(30, 1)
        csr_name = find_val_by_key(db_df, ["CSRæ–‡ä»¶åç§°"]) or get_db_val(31, 1)
        csr_date_raw = find_val_by_key(db_df, ["CSRæ–‡ä»¶æ—¥æœŸ"]) or get_db_val(32, 1)
        
        csr_date = str(csr_date_raw).replace(" 00:00:00", "").strip()
        if csr_date.lower() == 'nan': csr_date = ""
        
        if customer_name or supplier_code or csr_name:
            customers_list.append({
                "Name": customer_name,
                "SupplierCode": supplier_code,
                "NameCSRDocument": csr_name,
                "DateCSRDocument": csr_date
            })

    # ğŸ’¥ [æ–°å¢ï¼šEMSæ‰©å±•åœºæ‰€ åŠ¨æ€å…¨é‡æå–ä¸åœ°å€åˆ‡åˆ†]
    ems_sites = []
    if not info_df.empty:
        header_r = -1
        col_map = {}
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                val = str(info_df.iloc[r, c]).strip().upper()
                # å…¼å®¹å¤šç§å¸¸è§çš„ EMS è¡¨å¤´åç§°
                if "EMSæ‰©å±•åœºæ‰€ä¿¡æ¯" in val or "æ‰©å±•åˆ¶é€ åœºæ‰€" in val or "æ‰©å±•ç°åœº" in val:
                    header_r = r
                    for c_scan in range(info_df.shape[1]):
                        h_val = str(info_df.iloc[r, c_scan]).strip()
                        if "ä¸­æ–‡åç§°" in h_val: col_map['name_cn'] = c_scan
                        elif "è‹±æ–‡åç§°" in h_val: col_map['name_en'] = c_scan
                        elif "ä¸­æ–‡åœ°å€" in h_val: col_map['addr_cn'] = c_scan
                        elif "è‹±æ–‡åœ°å€" in h_val: col_map['addr_en'] = c_scan
                        elif "é‚®ç¼–" in h_val or "é‚®æ”¿ç¼–ç " in h_val: col_map['zip'] = c_scan
                        elif "USI" in h_val.upper(): col_map['usi'] = c_scan
                        elif "äººæ•°" in h_val: col_map['emp'] = c_scan
                    break
            if header_r != -1: break
                
        if header_r != -1:
            for r in range(header_r + 1, info_df.shape[0]):
                def safe_get_cell(row, col_idx):
                    if col_idx == -1: return ""
                    v = str(info_df.iloc[row, col_idx]).strip()
                    return "" if v.lower() == 'nan' else v

                name_cn = safe_get_cell(r, col_map.get('name_cn', -1))
                name_en = safe_get_cell(r, col_map.get('name_en', -1))
                addr_cn = safe_get_cell(r, col_map.get('addr_cn', -1))
                
                # å¦‚æœé‡åˆ°ç©ºè¡Œï¼Œè·³è¿‡ï¼›å¦‚æœé‡åˆ°å…¶ä»–æ¨¡å—è¡¨å¤´ï¼Œè·³è¿‡
                if not name_cn and not addr_cn: continue
                if "åç§°" in name_cn and "åœ°å€" in addr_cn: continue
                
                # æ‹¼æ¥ä¸­è‹±æ–‡åç§°
                full_site_name = name_cn
                if name_en and name_en not in name_cn:
                    full_site_name = f"{name_cn} {name_en}".strip()

                addr_en = safe_get_cell(r, col_map.get('addr_en', -1))
                zip_code = safe_get_cell(r, col_map.get('zip', -1))
                usi = safe_get_cell(r, col_map.get('usi', -1))
                emp = safe_get_cell(r, col_map.get('emp', -1))

                # æ‰§è¡Œå€’åºåˆ‡åˆ†
                ems_street, ems_city, ems_state, ems_country = addr_en, "", "", ""
                if addr_en:
                    clean_eng = addr_en.replace('ï¼Œ', ',')
                    parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
                    if len(parts) >= 3:
                        ems_country = parts[-1]
                        ems_state = parts[-2]
                        ems_city = parts[-3]
                        ems_street = ", ".join(parts[:-3])
                    else:
                        ems_street = addr_en

                site_obj = {
                    "Id": str(uuid.uuid4()),
                    "SiteName": full_site_name,
                    "IATF_USI": usi,
                    "TotalNumberEmployees": emp,
                    "AddressNative": {
                        "Street1": addr_cn,
                        "City": "",
                        "State": "",
                        "Country": "ä¸­å›½",
                        "PostalCode": zip_code
                    },
                    "Address": {
                        "Street1": ems_street,
                        "City": ems_city,
                        "State": ems_state,
                        "Country": ems_country,
                        "PostalCode": zip_code
                    }
                }
                ems_sites.append(site_obj)

    # [ç»ˆæé˜²å¼¹åœ°å€æ‰«æ (ä¸»åœ°å€)]
    english_address = ""
    native_street = ""
    
    def get_adjacent_cells(df, keywords):
        cands = []
        if df.empty: return cands
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                val = str(df.iloc[r, c]).strip().upper()
                for k in keywords:
                    if k.upper() in val:
                        if c + 1 < df.shape[1]: cands.append(str(df.iloc[r, c+1]))
                        if c + 2 < df.shape[1]: cands.append(str(df.iloc[r, c+2]))
                        if c + 3 < df.shape[1]: cands.append(str(df.iloc[r, c+3]))
                        if c + 4 < df.shape[1]: cands.append(str(df.iloc[r, c+4]))
        return [str(x).strip() for x in cands if str(x).strip() and str(x).lower() != 'nan']

    raw_cands = get_adjacent_cells(info_df, ["å®¡æ ¸åœ°å€", "AUDIT ADDRESS", "ADDRESS"]) + \
                get_adjacent_cells(db_df, ["åœ°å€", "ADDRESS"])
                
    en_candidates = []
    zh_candidates = []

    for cand in raw_cands:
        lines = cand.replace('\r', '\n').split('\n')
        en_parts = []
        zh_parts = []
        for line in lines:
            line = line.strip()
            if not line: continue
            if re.search(r'[\u4e00-\u9fff]', line):
                zh_parts.append(line)
            elif re.search(r'[a-zA-Z]', line):
                en_parts.append(line)
        
        if en_parts: en_candidates.append(" ".join(en_parts))
        if zh_parts: zh_candidates.append(" ".join(zh_parts))

    english_address = max(en_candidates, key=len) if en_candidates else ""
    native_street = max(zh_candidates, key=len) if zh_candidates else ""

    if not english_address:
        for df in [info_df, db_df]:
            if df.empty: continue
            for r in range(df.shape[0]):
                for c in range(df.shape[1]):
                    val = str(df.iloc[r, c]).strip()
                    val_upper = val.upper()
                    if ("PROVINCE" in val_upper or "CITY" in val_upper) and re.search(r'[a-zA-Z]', val):
                        lines = val.replace('\r', '\n').split('\n')
                        en_parts = [l.strip() for l in lines if not re.search(r'[\u4e00-\u9fff]', l) and re.search(r'[a-zA-Z]', l)]
                        if en_parts:
                            cand = " ".join(en_parts)
                            if len(cand) > len(english_address):
                                english_address = cand

    street, city, state, country = english_address, "", "", ""
    if english_address:
        clean_eng = english_address.replace('ï¼Œ', ',')
        parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
        if len(parts) >= 3:
            country = parts[-1]
            state = parts[-2]
            city = parts[-3]
            street = ", ".join(parts[:-3])
        else:
            street = english_address

    # ================= 3. å®šç‚¹æ›¿æ¢å…¥ final_json =================

    final_json["uuid"] = str(uuid.uuid4())
    final_json["created"] = int(time.time() * 1000)

    # A. å®¡æ ¸æ•°æ®
    ensure_path(final_json, ["AuditData", "AuditDate"])
    if start_iso: final_json["AuditData"]["AuditDate"]["Start"] = start_iso
    if end_iso: final_json["AuditData"]["AuditDate"]["End"] = end_iso
    final_json["AuditData"]["CbIdentificationNo"] = find_val_by_key(db_df, ["è®¤è¯æœºæ„æ ‡è¯†å·"]) or get_db_val(2, 4)
    
    # ğŸ’¥ AuditorName ä¿æŒåŸå§‹æœªå¤„ç†æ–‡æœ¬
    final_json["AuditData"]["AuditorName"] = raw_name
    final_json["AuditData"]["auditorname"] = raw_name

    if "AuditTeam" not in final_json["AuditData"] or not isinstance(final_json["AuditData"]["AuditTeam"], list) or len(final_json["AuditData"]["AuditTeam"]) == 0:
        final_json["AuditData"]["AuditTeam"] = [{}]
        
    team = final_json["AuditData"]["AuditTeam"][0]
    if isinstance(team, dict):
        team.update({
            "Name": formatted_team_name, # ğŸ’¥ å‰ç«¯ Name åº”ç”¨æ ¼å¼åŒ–è‹±æ–‡å
            "CaaNo": caa_no,
            "AuditorId": auditor_id, 
            "AuditDaysPerformed": 1.5,
            "DatesOnSite": [{"Date": start_iso, "Day": 1}, {"Date": end_iso, "Day": 0.5}]
        })

    # B. ç»„ç»‡ä¸åœ°å€ä¿¡æ¯ 
    ensure_path(final_json, ["OrganizationInformation", "AddressNative"])
    ensure_path(final_json, ["OrganizationInformation", "Address"])
    org = final_json["OrganizationInformation"]
    
    org["OrganizationName"] = find_val_by_key(db_df, ["ç»„ç»‡åç§°"]) or get_db_val(1, 4)
    org["IndustryCode"] = find_val_by_key(db_df, ["è¡Œä¸šä»£ç ", "Industry Code"])
    org["IATF_USI"] = find_val_by_key(db_df, ["IATF USI", "USI"]) or get_db_val(3, 4)
    org["TotalNumberEmployees"] = find_val_by_key(db_df, ["åŒ…æ‹¬æ‰©å±•ç°åœºåœ¨å†…çš„å‘˜å·¥æ€»æ•°", "å‘˜å·¥æ€»æ•°"]) or get_db_val(27, 1)
    org["CertificateScope"] = find_val_by_key(db_df, ["è¯ä¹¦èŒƒå›´"])
    org["Representative"] = find_val_by_key(db_df, ["ç»„ç»‡ä»£è¡¨", "ç®¡ç†è€…ä»£è¡¨", "è”ç³»äºº", "Representative"]) or get_db_val(15, 1)
    org["Telephone"] = find_val_by_key(db_df, ["è”ç³»ç”µè¯", "ç”µè¯", "Telephone"]) or get_db_val(15, 4)
    extracted_email = find_val_by_key(db_df, ["ç”µå­é‚®ç®±", "é‚®ç®±", "Email", "E-mail"]) or get_db_val(16, 1)
    org["Email"] = "" if str(extracted_email).strip() == "0" else extracted_email
    
    if "LanguageByManufacturingPersonnel" in org:
        lang_node = org["LanguageByManufacturingPersonnel"]
        if isinstance(lang_node, list) and len(lang_node) > 0:
            if isinstance(lang_node[0], dict): lang_node[0]["Products"] = ""
        elif isinstance(lang_node, dict):
            if "0" in lang_node and isinstance(lang_node["0"], dict): lang_node["0"]["Products"] = ""
            else: lang_node["Products"] = ""
    
    org["AddressNative"].update({
        "Street1": native_street,
        "State": "", "City": "", "Country": "ä¸­å›½",
        "PostalCode": find_val_by_key(db_df, ["é‚®æ”¿ç¼–ç "]) or get_db_val(10, 4)
    })
    
    org["Address"].update({
        "State": state, "City": city, "Country": country, "Street1": street,
        "PostalCode": find_val_by_key(db_df, ["é‚®æ”¿ç¼–ç "]) or get_db_val(10, 4)
    })

    # ğŸ’¥ ã€ä¿®æ”¹ç‚¹ã€‘ï¼šå°† EMS èµ‹äºˆæ ¹èŠ‚ç‚¹ï¼Œå¹¶åŒæ­¥æ›´æ–°æ ‡å¿—ä½
    if ems_sites:
        final_json["ExtendedManufacturingSites"] = ems_sites
        org["ExtendedManufacturingSite"] = "1"
    else:
        org["ExtendedManufacturingSite"] = "0"

    # C. é¡¾å®¢ä¸ CSR 
    ensure_path(final_json, ["CustomerInformation"])
    final_json["CustomerInformation"]["Customers"] = []
    
    for c_info in customers_list:
        cust_obj = {
            "Id": str(uuid.uuid4()),
            "Name": c_info["Name"],
            "SupplierCode": c_info["SupplierCode"],
            "Csrs": [
                {
                    "Id": str(uuid.uuid4()), 
                    "Name": c_info["Name"], 
                    "SupplierCode": c_info["SupplierCode"],
                    "NameCSRDocument": c_info["NameCSRDocument"],
                    "DateCSRDocument": c_info["DateCSRDocument"]
                }
            ]
        }
        final_json["CustomerInformation"]["Customers"].append(cust_obj)

    # D. æ–‡ä»¶æ¸…å•å®šç‚¹æ›¿æ¢
    docs_list = []
    if not doc_list_df.empty:
        for c in range(doc_list_df.shape[1]):
            for r in range(doc_list_df.shape[0]):
                cell_val = str(doc_list_df.iloc[r, c]).strip()
                if "å…¬å¸å†…å¯¹åº”çš„ç¨‹åºæ–‡ä»¶" in cell_val or "åŒ…å«åç§°ã€ç¼–å·ã€ç‰ˆæœ¬" in cell_val:
                    for r2 in range(r + 1, doc_list_df.shape[0]):
                        val = str(doc_list_df.iloc[r2, c]).strip()
                        if val and val.lower() != 'nan':
                            docs_list.append(val)
                    break
            if docs_list: break

    if docs_list:
        ensure_path(final_json, ["Stage1DocumentedRequirements"])
        if "IatfClauseDocuments" not in final_json["Stage1DocumentedRequirements"] or not isinstance(final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"], list):
            final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"] = []
            
        clause_docs = final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"]
        for i, doc_name in enumerate(docs_list):
            if i < len(clause_docs):
                if isinstance(clause_docs[i], dict):
                    clause_docs[i]["DocumentName"] = doc_name
            else:
                clause_docs.append({"DocumentName": doc_name})

    # E. è¿‡ç¨‹æ¸…å•é‡å»º
    processes = []
    if not proc_df.empty:
        clause_cols = proc_df.columns[13:] if proc_df.shape[1] > 13 else









