import streamlit as st
import pandas as pd
import json
import uuid
import time
import os
import copy
import re
from datetime import datetime, timedelta

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="IATF å®¡è®¡è½¬æ¢å·¥å…· (v57.0 ä¸»åœ°å€æ”»å…‹ç‰ˆ)",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# --- 1. ä¾§è¾¹æ ï¼šæ¨¡æ¿åŠ è½½ ---
with st.sidebar:
    st.header("âš™ï¸ æ¨¡æ¿é…ç½®")
    
    st.info("ğŸ’¡ è¯·ä¸Šä¼ æ‚¨çš„ JSON æ¨¡æ¿ã€‚ç¨‹åºå°†æŠŠè¯¥æ–‡ä»¶ä½œä¸ºå®Œæ•´çš„åº•å±‚éª¨æ¶ã€‚")
    user_template_file = st.file_uploader("ä¸Šä¼ åŸºç¡€ JSON æ¨¡æ¿", type=["json"])
    
    base_template_data = None
    if user_template_file:
        try:
            base_template_data = json.load(user_template_file)
            st.success(f"âœ… æˆåŠŸåŠ è½½åº•åº§æ¨¡æ¿: {user_template_file.name}")
        except Exception as e:
            st.error(f"âŒ æ¨¡æ¿è§£æå¤±è´¥: {e}")
            st.stop()
    else:
        st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  JSON æ¨¡æ¿æ–‡ä»¶ã€‚")
        st.stop()

# --- è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨å¯»å€ ---
def ensure_path(d, path):
    current = d
    for key in path:
        if key not in current or not isinstance(current[key], dict):
            current[key] = {}
        current = current[key]
    return current

def safe_get(obj, key, default=""):
    if isinstance(obj, dict):
        return obj.get(key, default)
    return default

# --- æ ¸å¿ƒè½¬æ¢é€»è¾‘ ---
def generate_json_logic(excel_file, base_data):
    final_json = copy.deepcopy(base_data)
    
    try:
        xls = pd.ExcelFile(excel_file)
        db_df = pd.read_excel(xls, sheet_name='æ•°æ®åº“', header=None) if 'æ•°æ®åº“' in xls.sheet_names else pd.read_excel(xls, sheet_name=0, header=None)
        proc_df = pd.read_excel(xls, sheet_name='è¿‡ç¨‹æ¸…å•') if 'è¿‡ç¨‹æ¸…å•' in xls.sheet_names else pd.DataFrame()
        info_df = pd.read_excel(xls, sheet_name='ä¿¡æ¯', header=None) if 'ä¿¡æ¯' in xls.sheet_names else pd.DataFrame()
        doc_list_df = pd.read_excel(xls, sheet_name=xls.sheet_names[8], header=None) if len(xls.sheet_names) >= 9 else pd.DataFrame()
    except Exception as e:
        raise ValueError(f"Excel è¯»å–å¤±è´¥: {str(e)}")

    def find_val_by_key(df, keywords, col_offset=1):
        if df.empty: return ""
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                cell_val = str(df.iloc[r, c]).strip()
                for k in keywords:
                    if k in cell_val:
                        if c + col_offset < df.shape[1]:
                            return str(df.iloc[r, c + col_offset]).strip()
        return ""
        
    def get_db_val(r, c):
        try:
            val = db_df.iloc[r, c]
            return str(val).strip() if pd.notna(val) else ""
        except: return ""

    # ================= 2. æ•°æ®æå– =================
    
    # [è¾…åŠ©å‡½æ•°ï¼šæš´åŠ›å‰¥ç¦»æ‰€æœ‰éè‹±æ–‡å­—æ¯ï¼Œå¹¶é‡æ’å¤§å°å†™]
    def extract_and_format_english_name(raw_val):
        clean_val = str(raw_val).replace("å§“å:", "").replace("Name:", "").strip()
        if not clean_val: return ""
        
        eng_only = re.sub(r'[^a-zA-Z\s]', ' ', clean_val).strip()
        eng_only = re.sub(r'\s+', ' ', eng_only)
        
        if eng_only:
            parts = eng_only.split()
            if len(parts) >= 2 and parts[0].isupper() and not parts[1].isupper():
                return f"{parts[1]} {parts[0]}"
            else:
                return eng_only
        return clean_val

    # [å…¨å±€å§“åï¼šä¿æŒåŸå§‹ä¸­æ–‡ä¸å¤„ç†ï¼Œä¾› AuditData ä½¿ç”¨]
    raw_name_full = find_val_by_key(db_df, ["å§“å", "Auditor Name"]) or get_db_val(5, 1)
    raw_name = raw_name_full.replace("å§“å:", "").replace("Name:", "").strip() if raw_name_full else ""

    # [ç”Ÿæˆæ ¼å¼åŒ–åçš„è‹±æ–‡åï¼Œä¸“é—¨ä¾› AuditTeam çš„ Name ä½¿ç”¨]
    formatted_team_name = extract_and_format_english_name(raw_name_full)

    # [CCAA]
    ccaa_raw = find_val_by_key(db_df, ["å®¡æ ¸å‘˜CCAA", "CCAA"]) or get_db_val(4, 1)
    caa_no = ""
    if ccaa_raw:
        match = re.search(r'(?:CCAA[:ï¼š\s-])\s*(.*)', ccaa_raw, re.IGNORECASE | re.DOTALL)
        caa_no = match.group(1).strip() if match else ccaa_raw.strip()

    # [AuditorId]
    auditor_id = ""
    if not info_df.empty:
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                cell_text = str(info_df.iloc[r, c])
                if "IATF Card" in cell_text or "IATFå¡å·" in cell_text:
                    if c + 1 < info_df.shape[1]:
                        raw_val = str(info_df.iloc[r, c + 1]).strip()
                        raw_val = raw_val.replace('\n', ' ').replace('\r', ' ')
                        auditor_id = re.sub(r'^IATF[:ï¼š\s-]*', '', raw_val, flags=re.IGNORECASE).strip()
                        if len(auditor_id) > 4: break
            if auditor_id and len(auditor_id) > 4: break

    # [å®¡æ ¸ä¸ç»“æœæ—¥æœŸ]
    start_date_raw = find_val_by_key(db_df, ["å®¡æ ¸å¼€å§‹æ—¥æœŸ", "å®¡æ ¸å¼€å§‹æ—¶é—´"]) or get_db_val(2, 1)
    end_date_raw = find_val_by_key(db_df, ["å®¡æ ¸ç»“æŸæ—¥æœŸ", "å®¡æ ¸ç»“æŸæ—¶é—´"]) or get_db_val(3, 1)
    
    def fmt_iso(val):
        try:
            clean_val = str(val).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
            dt = pd.to_datetime(clean_val, errors='coerce')
            if pd.notna(dt): return dt.strftime('%Y-%m-%d') + "T00:00:00.000Z"
        except: pass
        return ""
        
    start_iso, end_iso = fmt_iso(start_date_raw), fmt_iso(end_date_raw)
    
    next_audit_iso = ""
    try:
        clean_end = str(end_date_raw).replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
        end_dt = pd.to_datetime(clean_end, errors='coerce')
        if pd.notna(end_dt): next_audit_iso = (end_dt + timedelta(days=45)).strftime('%Y-%m-%d') + "T00:00:00.000Z"
    except: pass

    # [å¤šé¡¾å®¢ä¸ CSR åŠ¨æ€æå–]
    customers_list = []
    if not info_df.empty:
        header_r = -1
        col_map = {'cust': -1, 'name': -1, 'date': -1, 'code': -1}
        for r in range(info_df.shape[0]):
            row_str = " ".join([str(x) for x in info_df.iloc[r, :]]).upper()
            if "CUSTOMER" in row_str and ("CSR" in row_str or "TITLE" in row_str):
                header_r = r
                for c in range(info_df.shape[1]):
                    val = str(info_df.iloc[r, c]).strip().upper()
                    if "CUSTOMER" in val or "å®¢æˆ·" in val: col_map['cust'] = c
                    elif "CSR" in val or "TITLE" in val: col_map['name'] = c
                    elif "VERSION" in val or "DATE" in val or "ç‰ˆæœ¬" in val or "æ—¥æœŸ" in val: col_map['date'] = c
                    elif "ä¾›åº”å•†ä»£ç " in val or "SUPPLIER" in val or "CODE" in val: col_map['code'] = c
                break
                
        if header_r != -1:
            for r in range(header_r + 1, info_df.shape[0]):
                cust_val = str(info_df.iloc[r, col_map['cust']]).strip() if col_map['cust'] != -1 else ""
                if not cust_val or cust_val.lower() == 'nan': continue
                if "å®¡æ ¸å‘˜" in cust_val or "AUDIT" in cust_val.upper() or "NAME" in cust_val.upper(): break
                    
                name_val = str(info_df.iloc[r, col_map['name']]).strip() if col_map['name'] != -1 else ""
                date_val = str(info_df.iloc[r, col_map['date']]).strip() if col_map['date'] != -1 else ""
                code_val = str(info_df.iloc[r, col_map['code']]).strip() if col_map['code'] != -1 else ""
                
                final_date = date_val.replace(" 00:00:00", "").strip()

                customers_list.append({
                    "Name": cust_val,
                    "SupplierCode": code_val,
                    "NameCSRDocument": name_val,
                    "DateCSRDocument": final_date
                })

    if not customers_list:
        customer_name = find_val_by_key(db_df, ["é¡¾å®¢", "å®¢æˆ·åç§°"]) or get_db_val(29, 1)
        supplier_code = find_val_by_key(db_df, ["ä¾›åº”å•†ç¼–ç ", "ä¾›åº”å•†ä»£ç "]) or get_db_val(30, 1)
        csr_name = find_val_by_key(db_df, ["CSRæ–‡ä»¶åç§°"]) or get_db_val(31, 1)
        csr_date_raw = find_val_by_key(db_df, ["CSRæ–‡ä»¶æ—¥æœŸ"]) or get_db_val(32, 1)
        
        csr_date = str(csr_date_raw).replace(" 00:00:00", "").strip()
        if csr_date.lower() == 'nan': csr_date = ""
        
        if customer_name or supplier_code or csr_name:
            customers_list.append({
                "Name": customer_name,
                "SupplierCode": supplier_code,
                "NameCSRDocument": csr_name,
                "DateCSRDocument": csr_date
            })

    # [æ”¯æŒåœºæ‰€ (RL) åŠ¨æ€å…¨é‡æå–ä¸åœ°å€åˆ‡åˆ†]
    support_sites = []
    if not info_df.empty:
        header_r = -1
        col_map = {}
        for r in range(info_df.shape[0]):
            for c in range(info_df.shape[1]):
                val = str(info_df.iloc[r, c]).strip().upper()
                if "è¢«æ”¯æŒåœºæ‰€ä¿¡æ¯" in val or "RLæ”¯æŒåœºæ‰€" in val or "æ”¯æŒåœºæ‰€ä¿¡æ¯" in val:
                    header_r = r
                    for c_scan in range(info_df.shape[1]):
                        h_val = str(info_df.iloc[r, c_scan]).strip()
                        if "ä¸­æ–‡åç§°" in h_val: col_map['name_cn'] = c_scan
                        elif "è‹±æ–‡åç§°" in h_val: col_map['name_en'] = c_scan
                        elif "ä¸­æ–‡åœ°å€" in h_val: col_map['addr_cn'] = c_scan
                        elif "è‹±æ–‡åœ°å€" in h_val: col_map['addr_en'] = c_scan
                        elif "é‚®ç¼–" in h_val or "é‚®æ”¿ç¼–ç " in h_val: col_map['zip'] = c_scan
                        elif "USI" in h_val.upper(): col_map['usi'] = c_scan
                        elif "äººæ•°" in h_val: col_map['emp'] = c_scan
                        elif "æ”¯æŒåŠŸèƒ½" in h_val: col_map['func'] = c_scan
                    break
            if header_r != -1: break
                
        if header_r != -1:
            for r in range(header_r + 1, info_df.shape[0]):
                def safe_get_cell(row, col_idx):
                    if col_idx == -1: return ""
                    v = str(info_df.iloc[row, col_idx]).strip()
                    return "" if v.lower() == 'nan' else v

                name_cn = safe_get_cell(r, col_map.get('name_cn', -1))
                addr_cn = safe_get_cell(r, col_map.get('addr_cn', -1))
                
                if not name_cn and not addr_cn: continue
                if "åç§°" in name_cn and "åœ°å€" in addr_cn: continue
                    
                addr_en = safe_get_cell(r, col_map.get('addr_en', -1))
                zip_code = safe_get_cell(r, col_map.get('zip', -1))
                usi = safe_get_cell(r, col_map.get('usi', -1))
                emp = safe_get_cell(r, col_map.get('emp', -1))
                func = safe_get_cell(r, col_map.get('func', -1))

                rl_street, rl_city, rl_state, rl_country = addr_en, "", "", ""
                if addr_en:
                    clean_eng = addr_en.replace('ï¼Œ', ',')
                    parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
                    if len(parts) >= 3:
                        rl_country = parts[-1]
                        rl_state = parts[-2]
                        rl_city = parts[-3]
                        rl_street = ", ".join(parts[:-3])
                    else:
                        rl_street = addr_en

                site_obj = {
                    "Id": str(uuid.uuid4()),
                    "SiteName": name_cn,
                    "Comments": func,
                    "AddressNative": {
                        "Street1": addr_cn,
                        "City": "",
                        "State": "",
                        "Country": "ä¸­å›½",
                        "PostalCode": zip_code
                    },
                    "Address": {
                        "Street1": rl_street,
                        "City": rl_city,
                        "State": rl_state,
                        "Country": rl_country,
                        "PostalCode": zip_code
                    }
                }
                support_sites.append(site_obj)

    # ğŸ’¥ğŸ’¥ğŸ’¥ [ç»ˆæç»†èƒçº§åœ°å€æ··åˆå‰¥ç¦»æ‰«æ] ğŸ’¥ğŸ’¥ğŸ’¥
    english_address = ""
    native_street = ""
    
    cands = []
    # å¼ºåˆ¶åŠ ä¸Šæ•°æ®åº“ä¸­æœ€å¸¸è§„çš„åœ°å€åæ ‡ï¼ˆç¬¬10åˆ°14è¡Œï¼‰
    if not db_df.empty:
        for r_idx in range(9, 14):
            if r_idx < db_df.shape[0]:
                if 1 < db_df.shape[1]: cands.append(str(db_df.iloc[r_idx, 1]))
                if 4 < db_df.shape[1]: cands.append(str(db_df.iloc[r_idx, 4]))
                
    # é›·è¾¾å¯»æ‰¾æ‰€æœ‰â€œåœ°å€â€å­—çœ¼åŠå…¶å³ä¾§ã€ä¸‹æ–¹çš„å•å…ƒæ ¼ï¼ˆåŒ…å«è‡ªèº«ï¼‰
    def get_anchored(df, keywords):
        res = []
        if df.empty: return res
        for r in range(df.shape[0]):
            for c in range(df.shape[1]):
                val = str(df.iloc[r, c]).strip().upper()
                if any(k in val for k in keywords):
                    res.append(str(df.iloc[r, c]))  # æŠŠå¸¦ç€è¡¨å¤´çš„è‡ªèº«åŠ è¿›å»
                    if c + 1 < df.shape[1]: res.append(str(df.iloc[r, c+1]))
                    if c + 2 < df.shape[1]: res.append(str(df.iloc[r, c+2]))
                    if r + 1 < df.shape[0]: res.append(str(df.iloc[r+1, c]))
                    if r + 1 < df.shape[0] and c+1 < df.shape[1]: res.append(str(df.iloc[r+1, c+1]))
        return res
        
    cands += get_anchored(info_df, ["å®¡æ ¸åœ°å€", "AUDIT ADDRESS", "ADDRESS"])
    cands += get_anchored(db_df, ["åœ°å€", "ADDRESS"])
    
    en_parts = []
    zh_parts = []

    for cand in cands:
        cand = str(cand).strip()
        if not cand or cand.lower() == 'nan': continue
        
        # å‰¥ç¦»è¡¨å¤´
        cand = re.sub(r'^(å®¡æ ¸åœ°å€|ç»„ç»‡åœ°å€|ä¼ä¸šåœ°å€|åœ°å€|ç°åœºåœ°å€|AUDIT ADDRESS|ADDRESS)[\s:ï¼š]*', '', cand, flags=re.IGNORECASE).strip()
        if not cand: continue
        
        # åˆ‡åˆ†è¡Œï¼ˆä¸‡ä¸€ç”¨æˆ·ç”¨äº† Alt+Enterï¼‰
        lines = cand.replace('\r', '\n').split('\n')
        for line in lines:
            line = line.strip()
            if not line: continue
            
            has_zh = bool(re.search(r'[\u4e00-\u9fff]', line))
            has_en = bool(re.search(r'[a-zA-Z]{3,}', line)) # è‡³å°‘æœ‰3ä¸ªè‹±æ–‡å­—æ¯
            
            # ğŸ’¥ æœ€å¼ºçš„ä¸€æ­¥ï¼šå¦‚æœåŒä¸€è¡Œæ··å†™äº†ä¸­è‹±æ–‡ï¼
            if has_zh and has_en:
                # æŠŠä¸­æ–‡å­—ç¬¦å’Œä¸­æ–‡æ ‡ç‚¹å…¨éƒ¨å˜ä¸ºç©ºæ ¼ï¼Œæå–çº¯è‹±æ–‡åœ°å€
                en_str = re.sub(r'[\u4e00-\u9fff]', ' ', line)
                en_str = re.sub(r'[ï¼Œã€‚ï¼›ï¼ˆï¼‰]', ' ', en_str) 
                en_str = re.sub(r'\s+', ' ', en_str).strip(" ()-.,")
                
                # æŠŠè‹±æ–‡å­—æ¯å»æ‰ï¼Œä¿ç•™çº¯ä¸­æ–‡åœ°å€
                zh_str = re.sub(r'[a-zA-Z]', '', line)
                zh_str = re.sub(r'\s+', ' ', zh_str).strip(" ()-.,")
                
                if len(en_str) > 10: en_parts.append(en_str)
                if len(zh_str) > 5: zh_parts.append(zh_str)
            elif has_zh:
                zh_parts.append(line)
            elif has_en:
                en_parts.append(line)

    english_address = max(en_parts, key=len) if en_parts else ""
    native_street = max(zh_parts, key=len) if zh_parts else ""

    # å€’åºåˆ‡åˆ†
    street, city, state, country = english_address, "", "", ""
    if english_address:
        clean_eng = english_address.replace('ï¼Œ', ',')
        parts = [p.strip() for p in clean_eng.split(',') if p.strip()]
        if len(parts) >= 3:
            country = parts[-1]
            state = parts[-2]
            city = parts[-3]
            street = ", ".join(parts[:-3])
        else:
            street = english_address

    # ================= 3. å®šç‚¹æ›¿æ¢å…¥ final_json =================

    final_json["uuid"] = str(uuid.uuid4())
    final_json["created"] = int(time.time() * 1000)

    # A. å®¡æ ¸æ•°æ®
    ensure_path(final_json, ["AuditData", "AuditDate"])
    if start_iso: final_json["AuditData"]["AuditDate"]["Start"] = start_iso
    if end_iso: final_json["AuditData"]["AuditDate"]["End"] = end_iso
    final_json["AuditData"]["CbIdentificationNo"] = find_val_by_key(db_df, ["è®¤è¯æœºæ„æ ‡è¯†å·"]) or get_db_val(2, 4)
    
    # AuditorName ä¿æŒåŸå§‹æœªå¤„ç†æ–‡æœ¬
    final_json["AuditData"]["AuditorName"] = raw_name
    final_json["AuditData"]["auditorname"] = raw_name

    if "AuditTeam" not in final_json["AuditData"] or not isinstance(final_json["AuditData"]["AuditTeam"], list) or len(final_json["AuditData"]["AuditTeam"]) == 0:
        final_json["AuditData"]["AuditTeam"] = [{}]
        
    team = final_json["AuditData"]["AuditTeam"][0]
    if isinstance(team, dict):
        team.update({
            "Name": formatted_team_name, # å‰ç«¯ Name åº”ç”¨æ ¼å¼åŒ–è‹±æ–‡å
            "CaaNo": caa_no,
            "AuditorId": auditor_id, 
            "AuditDaysPerformed": 1.5,
            "DatesOnSite": [{"Date": start_iso, "Day": 1}, {"Date": end_iso, "Day": 0.5}]
        })

    # B. ç»„ç»‡ä¸åœ°å€ä¿¡æ¯ 
    ensure_path(final_json, ["OrganizationInformation", "AddressNative"])
    ensure_path(final_json, ["OrganizationInformation", "Address"])
    org = final_json["OrganizationInformation"]
    
    org["OrganizationName"] = find_val_by_key(db_df, ["ç»„ç»‡åç§°"]) or get_db_val(1, 4)
    org["IndustryCode"] = find_val_by_key(db_df, ["è¡Œä¸šä»£ç ", "Industry Code"])
    org["IATF_USI"] = find_val_by_key(db_df, ["IATF USI", "USI"]) or get_db_val(3, 4)
    org["TotalNumberEmployees"] = find_val_by_key(db_df, ["åŒ…æ‹¬æ‰©å±•ç°åœºåœ¨å†…çš„å‘˜å·¥æ€»æ•°", "å‘˜å·¥æ€»æ•°"]) or get_db_val(27, 1)
    org["CertificateScope"] = find_val_by_key(db_df, ["è¯ä¹¦èŒƒå›´"])
    org["Representative"] = find_val_by_key(db_df, ["ç»„ç»‡ä»£è¡¨", "ç®¡ç†è€…ä»£è¡¨", "è”ç³»äºº", "Representative"]) or get_db_val(15, 1)
    org["Telephone"] = find_val_by_key(db_df, ["è”ç³»ç”µè¯", "ç”µè¯", "Telephone"]) or get_db_val(15, 4)
    extracted_email = find_val_by_key(db_df, ["ç”µå­é‚®ç®±", "é‚®ç®±", "Email", "E-mail"]) or get_db_val(16, 1)
    org["Email"] = "" if str(extracted_email).strip() == "0" else extracted_email
    
    if "LanguageByManufacturingPersonnel" in org:
        lang_node = org["LanguageByManufacturingPersonnel"]
        if isinstance(lang_node, list) and len(lang_node) > 0:
            if isinstance(lang_node[0], dict): lang_node[0]["Products"] = ""
        elif isinstance(lang_node, dict):
            if "0" in lang_node and isinstance(lang_node["0"], dict): lang_node["0"]["Products"] = ""
            else: lang_node["Products"] = ""
    
    # ğŸ’¥ ã€ä¿®æ”¹ç‚¹ã€‘ï¼šå¦‚æœæå–æˆåŠŸæ‰å†™å…¥ï¼Œé˜²æ­¢ç©ºå­—ç¬¦ä¸²è¦†ç›–äº†åŸ JSON æ¨¡æ¿é‡Œå¯èƒ½æœ‰çš„å†…å®¹
    if native_street:
        org["AddressNative"]["Street1"] = native_street
    org["AddressNative"]["Country"] = "ä¸­å›½"
    
    if english_address:
        org["Address"]["State"] = state
        org["Address"]["City"] = city
        org["Address"]["Country"] = country if country else "China"
        org["Address"]["Street1"] = street
        
    postal_code = find_val_by_key(db_df, ["é‚®æ”¿ç¼–ç "]) or get_db_val(10, 4)
    if postal_code:
        org["AddressNative"]["PostalCode"] = postal_code
        org["Address"]["PostalCode"] = postal_code

    if support_sites:
        final_json["ProvidingSupportSites"] = support_sites

    # C. é¡¾å®¢ä¸ CSR 
    ensure_path(final_json, ["CustomerInformation"])
    final_json["CustomerInformation"]["Customers"] = []
    
    for c_info in customers_list:
        cust_obj = {
            "Id": str(uuid.uuid4()),
            "Name": c_info["Name"],
            "SupplierCode": c_info["SupplierCode"],
            "Csrs": [
                {
                    "Id": str(uuid.uuid4()), 
                    "Name": c_info["Name"], 
                    "SupplierCode": c_info["SupplierCode"],
                    "NameCSRDocument": c_info["NameCSRDocument"],
                    "DateCSRDocument": c_info["DateCSRDocument"]
                }
            ]
        }
        final_json["CustomerInformation"]["Customers"].append(cust_obj)

    # D. æ–‡ä»¶æ¸…å•å®šç‚¹æ›¿æ¢
    docs_list = []
    if not doc_list_df.empty:
        for c in range(doc_list_df.shape[1]):
            for r in range(doc_list_df.shape[0]):
                cell_val = str(doc_list_df.iloc[r, c]).strip()
                if "å…¬å¸å†…å¯¹åº”çš„ç¨‹åºæ–‡ä»¶" in cell_val or "åŒ…å«åç§°ã€ç¼–å·ã€ç‰ˆæœ¬" in cell_val:
                    for r2 in range(r + 1, doc_list_df.shape[0]):
                        val = str(doc_list_df.iloc[r2, c]).strip()
                        if val and val.lower() != 'nan':
                            docs_list.append(val)
                    break
            if docs_list: break

    if docs_list:
        ensure_path(final_json, ["Stage1DocumentedRequirements"])
        if "IatfClauseDocuments" not in final_json["Stage1DocumentedRequirements"] or not isinstance(final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"], list):
            final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"] = []
            
        clause_docs = final_json["Stage1DocumentedRequirements"]["IatfClauseDocuments"]
        for i, doc_name in enumerate(docs_list):
            if i < len(clause_docs):
                if isinstance(clause_docs[i], dict):
                    clause_docs[i]["DocumentName"] = doc_name
            else:
                clause_docs.append({"DocumentName": doc_name})

    # E. è¿‡ç¨‹æ¸…å•é‡å»º
    processes = []
    if not proc_df.empty:
        clause_cols = proc_df.columns[13:] if proc_df.shape[1] > 13 else []
        for idx, row in proc_df.iterrows():
            p_name = str(row.iloc[0]).strip()
            rep_name = str(row.iloc[2]).strip() if pd.notna(row.iloc[2]) else ""
            
            if not p_name or p_name.lower() == 'nan': continue
            proc_obj = {
                "Id": str(uuid.uuid4()),
                "ProcessName": p_name,
                "RepresentativeName": rep_name,
                "ManufacturingProcess": "0",
                "OnSiteProcess": "1",
                "RemoteProcess": "0",
                "AuditNotes": [{
                    "Id": str(uuid.uuid4()),
                    "AuditorId": auditor_id
                }]
            }
            for col in clause_cols:
                if str(row[col]).strip().upper() in ['X', 'TRUE']: proc_obj[col] = True
            processes.append(proc_obj)
    final_json["Processes"] = processes

    # F. ç»“æœæ—¥æœŸ
    if "Results" not in final_json: final_json["Results"] = {}
    if "AuditReportFinal" not in final_json["Results"]: final_json["Results"]["AuditReportFinal"] = {}
    
    if end_iso: final_json["Results"]["AuditReportFinal"]["Date"] = end_iso
    if next_audit_iso: final_json["Results"]["DateNextScheduledAudit"] = next_audit_iso
    
    b6_raw_val = get_db_val(5, 1)
    b6_formatted_name = extract_and_format_english_name(b6_raw_val)
    final_json["Results"]["AuditReportFinal"]["AuditorName"] = b6_formatted_name

    return final_json

# ================= ä¸»ç•Œé¢ =================
st.title("ğŸ›¡ï¸ å¤šæ¨¡æ¿å®¡è®¡è½¬æ¢å¼•æ“ (v57.0 ä¸»åœ°å€å½»åº•æ”»å…‹ç‰ˆ)")
st.markdown("ğŸ’¡ **ä¿®æ”¹æ—¥å¿—**ï¼šåŠ å…¥äº†**ç»†èƒçº§æ··æ’è¯†åˆ«é€»è¾‘**ï¼Œç°åœ¨å³ä¾¿ä½ çš„ä¸­è‹±æ–‡åœ°å€æŒ¤åœ¨åŒä¸€ä¸ªæ ¼å­é‡Œä¸”ä¸æ¢è¡Œï¼Œç¨‹åºä¹Ÿä¼šè‡ªåŠ¨æŠŠå®ƒä»¬å‰¥ç¦»æå–ï¼")

uploaded_files = st.file_uploader("ğŸ“¥ ä¸Šä¼  Excel æ•°æ®è¡¨", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    st.divider()
    for file in uploaded_files:
        try:
            res_json = generate_json_logic(file, base_template_data)
            st.success(f"âœ… {file.name} è½¬æ¢æˆåŠŸ")
            
            with st.expander("ğŸ‘€ æŸ¥çœ‹è¯Šæ–­é¢æ¿ (åœ°å€æ··æ’æå–æ ¡éªŒ)", expanded=True):
                 st.code(f"""
ã€OrganizationInformation ä¸»åœ°å€ç”Ÿæˆç¡®è®¤ã€‘
Street1 (ä¸­æ–‡):  "{safe_get(res_json.get('OrganizationInformation', {}).get('AddressNative', {}), 'Street1', 'ç¼ºå¤±')}"
Street1 (è‹±æ–‡):  "{safe_get(res_json.get('OrganizationInformation', {}).get('Address', {}), 'Street1', 'ç¼ºå¤±')}"
City (è‹±æ–‡):     "{safe_get(res_json.get('OrganizationInformation', {}).get('Address', {}), 'City', 'ç¼ºå¤±')}"
                 """.strip(), language="yaml")

            st.download_button(
                label=f"ğŸ“¥ ä¸‹è½½ JSON ({file.name})",
                data=json.dumps(res_json, indent=2, ensure_ascii=False),
                file_name=file.name.replace(".xlsx", ".json"),
                key=f"dl_{file.name}"
            )
        except Exception as e:
            st.error(f"âŒ {file.name} æ ¸å¿ƒå¤„ç†å¤±è´¥: {str(e)}")






